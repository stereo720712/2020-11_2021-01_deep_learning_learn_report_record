{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0-dev20201101\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# 安装tfds pip install tfds-nightly==1.0.2.dev201904090105\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import sys\n",
    "import fox_proxy\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('.')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tfds load test data \n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True, as_supervised=True,download=False)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus((en.numpy() for pt, en in train_examples),\n",
    "                                                                         target_vocab_size=2**13)\n",
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus((pt.numpy() for en, pt in train_examples),\n",
    "                                                                         target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_string is [7915, 1248, 7946, 7194, 13, 2799]\n",
      "The original string is Transformer is awesome\n",
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# sample  to encoding\n",
    "sample_string = 'Transformer is awesome'\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print('tokenized_string is {}'.format(tokenized_string))\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print('The original string is {}'.format(original_string))\n",
    "assert original_string == sample_string\n",
    "# 如果单词不在词典中，则分词器（tokenizer）通过将单词分解为子词来对字符串进行编码。\n",
    "for ts in tokenized_string:\n",
    "    print('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将开始和结束标记（token）添加到输入和目标。\n",
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "    lang1.numpy()) + [tokenizer_pt.vocab_size + 1]\n",
    "    \n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "    lang2.numpy()) + [tokenizer_en.vocab_size + 1]\n",
    "    \n",
    "    return lang1, lang2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note：为了使本示例较小且相对较快，删除长度大于40个标记的样本。\n",
    "MAX_LENGTH = 40\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x)<= max_length,\n",
    "                         tf.size(y)<= max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode in tf\n",
    "def tf_encode(pt, en):\n",
    "    result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64,tf.int64])\n",
    "    result_pt.set_shape([None])\n",
    "    result_en.set_shape([None])\n",
    "    return result_pt, result_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[8087 2978 1942 ...    0    0    0]\n",
      " [8087 1949 4957 ...    0    0    0]\n",
      " [8087 7682 1786 ...    0    0    0]\n",
      " ...\n",
      " [8087  830 2578 ...    0    0    0]\n",
      " [8087 5421    9 ...    0    0    0]\n",
      " [8087 1091 7863 ...    0    0    0]], shape=(64, 40), dtype=int64) tf.Tensor(\n",
      "[[8087   98   25 ...    0    0    0]\n",
      " [8087   12   20 ...    0    0    0]\n",
      " [8087   12 5453 ...    0    0    0]\n",
      " ...\n",
      " [8087  115   11 ...    0    0    0]\n",
      " [8087   25   22 ...    0    0    0]\n",
      " [8087   15  381 ...    0    0    0]], shape=(64, 25), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset\n",
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "#print('pause')\n",
    "# 将数据集缓存到内存中以加快读取速度。\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset =train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)\n",
    "\n",
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "print(pt_batch, en_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# position encoding\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2) / np.float32(d_model)))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def position_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "    # sin in position indices is even , 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:,0::2])\n",
    "    # cos in position indices is odd , 2i+1\n",
    "    angle_rads[:,1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    position_encoding = angle_rads[np.newaxis,...]\n",
    "    return tf.cast(position_encoding, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# position encoding layer\n",
    "pos_encoding = position_encoding(50, 512)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 1. 0.]]]\n",
      "\n",
      "\n",
      " [[[0. 0. 0. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(3, 1, 1, 5), dtype=float32)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "遮挡（Masking）\n",
    "\n",
    "遮挡一批序列中所有的填充标记（pad tokens）。\n",
    "这确保了模型不会将填充作为输入。\n",
    "该 mask 表明填充值 0 出现的位置：在这些位置 mask 输出 1，否则输出 0。\n",
    "'''\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    # 添加额外的维度来将填充加到\n",
    "    # 注意力对数（logits）。\n",
    "    return seq[:,tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "# test padding mask\n",
    "x = tf.constant([[7,6,0,0,1],[1,2,3,0,0],[0,0,0,4,5]])\n",
    "print(create_padding_mask(x))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "前瞻遮挡（look-ahead mask）用于遮挡一个序列中的后续标记（future tokens）。\n",
    "换句话说，该 mask 表明了不应该使用的条目。\n",
    "\n",
    "这意味着要预测第三个词，将仅使用第一个和第二个词。\n",
    "与此类似，预测第四个词，仅使用第一个，第二个和第三个词，依此类推。\n",
    "'''\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size,size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "# test look_ahead_mask\n",
    "x = tf.random.uniform((1,3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "print(temp)\n",
    "print(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按比缩放的点积注意力（Scaled dot product attention）\n",
    "# Attention qkv formula\n",
    "# img/attention_formula.sv\n",
    "# https://tensorflow.google.cn/images/tutorials/transformer/scaled_attention.png\n",
    "def scaled_dot_product_attention(q,k,v,mask):\n",
    "    \"\"\"计算注意力权重。\n",
    "     q, k, v 必须具有匹配的前置维度。\n",
    "     k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
    "     虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
    "     但是 mask 必须能进行广播转换以便求和。\n",
    "\n",
    "     参数:\n",
    "       q: 请求的形状 == (..., seq_len_q, depth)\n",
    "       k: 主键的形状 == (..., seq_len_k, depth)\n",
    "       v: 数值的形状 == (..., seq_len_v, depth_v)\n",
    "       mask: Float 张量，其形状能转换成\n",
    "             (..., seq_len_q, seq_len_k)。默认为None。\n",
    "\n",
    "     返回值:\n",
    "       输出，注意力权重\n",
    "     \"\"\"\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    # 缩放 matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1],tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add  mask\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    attention_Weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_Weights, v)\n",
    "    return output, attention_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "当 softmax 在 K 上进行归一化后，它的值决定了分配到 Q 的重要程度。\n",
    "\n",
    "输出表示注意力权重和 V（数值）向量的乘积。这确保了要关注的词保持原样，而无关的词将被清除掉。\n",
    "'''\n",
    "def print_out(q,k,v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "        q, k, v, None)\n",
    "    print('Attention weights are :')\n",
    "    print(temp_attn)\n",
    "    print('Output is:')\n",
    "    print(temp_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                     [0,10,0],\n",
    "                     [0,0,10],\n",
    "                     [0,0,10]], dtype=tf.float32)\n",
    "\n",
    "temp_v = tf.constant([[1,0],\n",
    "                      [10,0],\n",
    "                      [100,5],\n",
    "                      [1000,6]],dtype=tf.float32)\n",
    "\n",
    "#test\n",
    "# query 符合第二個主鍵 (key)\n",
    "# 返回 第二個數值\n",
    "temp_q = tf.constant([[0,10,0]],dtype=tf.float32)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# query 符合 第三個跟第四個key\n",
    "# 因此對所有的相關數值娶了平均\n",
    "temp_q = tf.constant([[0,0,10]],dtype=tf.float32)\n",
    "print_out(temp_q, temp_k, temp_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 这条请求符合第一和第二条主键，\n",
    "# 因此，对它们的数值去了平均。\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are :\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 将所有请求一起传递。\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "多头注意力由四部分组成：\n",
    "\n",
    "    线性层并分拆成多头。\n",
    "    按比缩放的点积注意力。\n",
    "    多头及联。\n",
    "    最后一层线性层。\n",
    "\n",
    "每个多头注意力块有三个输入：Q（请求）、K（主键）、V（数值）。这些输入经过线性（Dense）层，并分拆成多头。\n",
    "\n",
    "将上面定义的 scaled_dot_product_attention 函数应用于每个头（进行了广播（broadcasted）以提高效率）。\n",
    "注意力这步必须使用一个恰当的 mask。然后将每个头的注意力输出连接起来（用tf.transpose 和 tf.reshape），\n",
    "并放入最后的 Dense 层。\n",
    "\n",
    "Q、K、和 V 被拆分到了多个头，而非单个的注意力头，因为多头允许模型共同注意来自不同表示空间的不同位置的信息。\n",
    "在分拆后，每个头部的维度减少，因此总的计算成本与有着全部维度的单个注意力头相同。\n",
    "'''\n",
    "# multi-head attention layer\n",
    "# https://tensorflow.google.cn/images/tutorials/transformer/multi_head_attention.png\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "       \n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads # floor divide\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"分拆最后一个维度到 (num_heads, depth).\n",
    "           转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  #(batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size) # same\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        # (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention) # (batch_size, seq_len_q,d_model)\n",
    "        return output, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 50, 512]), TensorShape([1, 8, 50, 50]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "创建一个 MultiHeadAttention 层进行尝试。在序列中的每个位置 y，MultiHeadAttention\n",
    "在序列中的所有其他位置运行所有8个注意力头，在每个位置y，返回一个新的同样长度的向量。\n",
    "\n",
    "'''\n",
    "# test\n",
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1,50,512)) # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(v = y, k=y, q=y,mask=None)\n",
    "out.shape, attn.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "点式前馈网络（Point wise feed forward network）\n",
    "\n",
    "点式前馈网络由两层全联接层组成，两层之间有一个 ReLU 激活函数。\n",
    "'''\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    FF = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'), # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model) #(batch_size, seq_len, d_model)\n",
    "    ])\n",
    "    return FF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "sample_ffn = point_wise_feed_forward_network(512, 2028)\n",
    "sample_ffn(tf.random.uniform((64,50,512))).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoder\n",
    "'''\n",
    "Transformer 模型与标准的具有注意力机制的序列到序列模型（sequence to sequence with attention model），遵循相同的一般模式。\n",
    "\n",
    "    输入语句经过 N 个编码器层，为序列中的每个词/标记生成一个输出。\n",
    "    解码器关注编码器的输出以及它自身的输入（自注意力）来预测下一个词。\n",
    "\n",
    "编码器层（Encoder layer）\n",
    "\n",
    "每个编码器层包括以下子层：\n",
    "\n",
    "    多头注意力（有填充遮挡）\n",
    "    点式前馈网络（Point wise feed forward networks）。\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。残差连接有助于避免深度网络中的梯度消失问题。\n",
    "\n",
    "每个子层的输出是 LayerNorm(x + Sublayer(x))。归一化是在 d_model（最后一个）维度完成的。Transformer 中有 N 个编码器层。\n",
    "'''\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask) # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output) #(batch_size, input_seq_len, d_model)\n",
    "        ffn_out = self.ffn(out1) # (batch_size, input_seq_len, d_model)\n",
    "        ffn_out = self.dropout2(ffn_out, training=training)\n",
    "        out2 = self.layernorm2(x + ffn_out)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sample_encoder_latyer_out = sample_encoder_layer(tf.random.uniform((64, 43, 512)),False,None)\n",
    "sample_encoder_latyer_out.shape #(batch_size, input_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------decoder layer\n",
    "'''\n",
    "解码器层（Decoder layer）\n",
    "\n",
    "每个解码器层包括以下子层：\n",
    "\n",
    "    遮挡的多头注意力（前瞻遮挡和填充遮挡）\n",
    "    多头注意力（用填充遮挡）。V（数值）和 K（主键）接收编码器输出作为输入。Q（请求）接收遮挡的多头注意力子层的输出。\n",
    "    点式前馈网络\n",
    "\n",
    "每个子层在其周围有一个残差连接，然后进行层归一化。每个子层的输出是 LayerNorm(x + Sublayer(x))。\n",
    "归一化是在 d_model（最后一个）维度完成的。\n",
    "\n",
    "Transformer 中共有 N 个解码器层。\n",
    "\n",
    "当 Q 接收到解码器的第一个注意力块的输出，并且 K 接收到编码器的输出时，注意力权重表示根据编码器的输出赋予解码器输入的重要性。\n",
    "换一种说法，解码器通过查看编码器输出和对其自身输出的自注意力，预测下一个词。参看按比缩放的点积注意力部分的演示。\n",
    "'''\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model,dff)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.droupout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.droupout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.droupout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_out.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x,x,x,look_ahead_mask) # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.droupout1(attn1,training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        # (batch_size, target_seq_len, d_model)\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask) \n",
    "        attn2 = self.droupout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2) # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.droupout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2) # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "sample_decoder_layer = DecoderLayer(512,8, 2048)\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64,50,512)), sample_encoder_latyer_out,False,None,None\n",
    ")\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------encoder\n",
    "'''\n",
    "编码器（Encoder）\n",
    "\n",
    "编码器 包括：\n",
    "\n",
    "    输入嵌入（Input Embedding）\n",
    "    位置编码（Positional Encoding）\n",
    "    N 个编码器层（encoder layers）\n",
    "\n",
    "输入经过嵌入（embedding）后，该嵌入与位置编码相加。该加法结果的输出是编码器层的输入。\n",
    "编码器的输出是解码器的输入\n",
    "'''\n",
    "# dff ??\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding,rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = position_encoding(maximum_position_encoding, self.d_model)\n",
    "        # dff parameter ?\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # 将嵌入和位置编码相加。\n",
    "        x =self.embedding(x) #(batch_size,input_seq_len,_d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model,tf.float32))\n",
    "        x += self.pos_encoding[:,:seq_len,:]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x,training, mask)\n",
    "        return x # (batch_size, input_seq_len, d_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64,62)),training=None,mask=None)\n",
    "print(sample_encoder_output.shape) # (batch_size, input_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decoder\n",
    "\n",
    "'''\n",
    "解码器（Decoder）\n",
    "\n",
    "解码器包括：\n",
    "\n",
    "    输出嵌入（Output Embedding）\n",
    "    位置编码（Positional Encoding）\n",
    "    N 个解码器层（decoder layers）\n",
    "\n",
    "目标（target）经过一个嵌入后，该嵌入和位置编码相加。\n",
    "该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。\n",
    "'''\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = position_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x) # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:,:seq_len, : ]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](\n",
    "                x, enc_output, training, look_ahead_mask, padding_mask\n",
    "            )\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "            \n",
    "        # x.shape (batch_size, tartet_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "output, attn = sample_decoder(tf.random.uniform((64,26)),\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              training=False, look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transformer  class\n",
    "'''\n",
    "创建 Transformer\n",
    "\n",
    "Transformer 包括编码器，解码器和最后的线性层。解码器的输出是线性层的输入，返回线性层的输出。\n",
    "'''\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_traget, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "        \n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_traget, rate)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask,\n",
    "             dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask) # (batch_size, inp_seq_len, d_model)\n",
    "        \n",
    "        # dec_ output (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, \n",
    "            look_ahead_mask, dec_padding_mask\n",
    "        ) \n",
    "        \n",
    "        final_output = self.final_layer(dec_output) #(batch_size, tar_seq_len, target_vocab_size)\n",
    "        return  final_output, attention_weights\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 26, 8000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=8500, target_vocab_size=8000,\n",
    "    pe_input=10000, pe_traget=6000\n",
    ")\n",
    "\n",
    "temp_input = tf.random.uniform((64,62))\n",
    "temp_target = tf.random.uniform((64,26))\n",
    "fn_out, _ = sample_transformer(temp_input,\n",
    "                               temp_target,\n",
    "                               training=False,\n",
    "                               enc_padding_mask=None,\n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "fn_out.shape # batch_size, tar_seq_len, target_vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tansformer Alog. Declare end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Training config\n",
    "\n",
    "## hyperparameters\n",
    "'''\n",
    "配置超参数（hyperparameters）\n",
    "\n",
    "为了让本示例小且相对较快，已经减小了num_layers、 d_model 和 dff 的值。\n",
    "\n",
    "Transformer 的基础模型使用的数值为：num_layers=6，d_model = 512，dff = 2048。关于所有其他版本的 Transformer，请查阅论文。\n",
    "\n",
    "Note：通过改变以下数值，您可以获得在许多任务上达到最先进水平的模型。\n",
    "'''\n",
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# optimizer ?\n",
    "'''\n",
    "优化器（Optimizer）\n",
    "\n",
    "根据论文中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。\n",
    "\n",
    "'''\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warm_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warm_steps** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "# test\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "'''\n",
    "损失函数与指标（Loss and metrics）\n",
    "\n",
    "由于目标序列是填充（padded）过的，因此在计算损失函数时，应用填充遮挡非常重要。\n",
    "'''\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real,pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.type)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "# test\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalCrossentropy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and checkpointing\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size,\n",
    "                          pe_input=input_vocab_size,\n",
    "                          pe_traget=target_vocab_size,\n",
    "                          rate=dropout_rate)\n",
    "\n",
    "#\n",
    "def create_masks(inp, tar):\n",
    "    #編碼器填充遮擋\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    #在編碼器的第二個注意力模塊使用\n",
    "    #該填充的遮擋用於遮擋解碼器的輸出\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # 在解碼器的第一個注意力模塊使用\n",
    "    # 用於填充(pad)和遮擋(mask)解碼器獲取到的輸入後的後續標記(future token)\n",
    "    look_ahead_mask = create_padding_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "\n",
    "# 創建檢查點的路徑和檢查點管理器(manager) , 用於每n個週期(epochs)保存檢查點\n",
    "checkpoint_path = './checkpoint/train'\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 如果檢查點存在，則恢復最新的檢查點\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "目标（target）被分成了 tar_inp 和 tar_real。tar_inp 作为输入传递到解码器。tar_real 是位移了 1 的同一个输入：\n",
    "在 tar_inp 中的每个位置，tar_real 包含了应该被预测到的下一个标记（token）。\n",
    "\n",
    "例如，sentence = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "tar_inp = \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "tar_real = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "Transformer 是一个自回归（auto-regressive）模型：它一次作一个部分的预测，然后使用到目前为止的自身的输出来决定下一步要做什么。\n",
    "\n",
    "在训练过程中，本示例使用了 teacher-forcing 的方法（就像文本生成教程中一样）。无论模型在当前时间步骤下预测出什么，teacher-forcing 方法都会将真实的输出传递到下一个时间步骤上。\n",
    "\n",
    "当 transformer 预测每个词时，自注意力（self-attention）功能使它能够查看输入序列中前面的单词，从而更好地预测下一个单词。\n",
    "\n",
    "为了防止模型在期望的输出上达到峰值，模型使用了前瞻遮挡（look-ahead mask）。\n",
    "'''\n",
    "\n",
    "EPOCHS = 20\n",
    "'''\n",
    "該 @tf.function 將追蹤-編譯train-step到TF圖中，以便更快地\n",
    "執行，該函數專用於參數張量的精確形狀，為了避免由於可變序列長度\n",
    "或可變批次大小(最後一批次較小)　導致的追蹤，使用input_signature\n",
    "指定更多的通用形狀\n",
    "'''\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None,None),dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,None), dtype=tf.float32)\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                     True,\n",
    "                                     enc_padding_mask,\n",
    "                                     combined_mask, #?\n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accurancy(tar_real, predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-38-9c346cd641ce>:36 train_step  *\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n    <ipython-input-37-c454183c2adb>:19 create_masks  *\n        look_ahead_mask = create_padding_mask(tf.shape(tar)[1])\n    <ipython-input-11-58af0505239c>:12 create_padding_mask  *\n        return seq[:,tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1047 _slice_helper\n        name=name)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1219 strided_slice\n        shrink_axis_mask=shrink_axis_mask)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10478 strided_slice\n        shrink_axis_mask=shrink_axis_mask, name=name)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:598 _create_op_internal\n        compute_device)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3536 _create_op_internal\n        op_def=op_def)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2016 __init__\n        control_input_ops, op_def)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Index out of range using input dim 0; input has only 0 dims for '{{node strided_slice_5}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=9, ellipsis_mask=0, end_mask=9, new_axis_mask=6, shrink_axis_mask=0](Cast_2, strided_slice_5/stack, strided_slice_5/stack_1, strided_slice_5/stack_2)' with input shapes: [], [4], [4], [4] and with computed input tensors: input[3] = <1 1 1 1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-12aa0d775971>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# inp -> portuguese, tar -> english\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    680\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    681\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 682\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2995\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2996\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2997\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2998\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3388\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3389\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3390\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3232\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3233\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3234\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3236\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    994\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    981\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-38-9c346cd641ce>:36 train_step  *\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n    <ipython-input-37-c454183c2adb>:19 create_masks  *\n        look_ahead_mask = create_padding_mask(tf.shape(tar)[1])\n    <ipython-input-11-58af0505239c>:12 create_padding_mask  *\n        return seq[:,tf.newaxis, tf.newaxis, :] # (batch_size, 1, 1, seq_len)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1047 _slice_helper\n        name=name)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1219 strided_slice\n        shrink_axis_mask=shrink_axis_mask)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10478 strided_slice\n        shrink_axis_mask=shrink_axis_mask, name=name)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:598 _create_op_internal\n        compute_device)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3536 _create_op_internal\n        op_def=op_def)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2016 __init__\n        control_input_ops, op_def)\n    c:\\programdata\\anaconda3\\envs\\py37_t2_2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Index out of range using input dim 0; input has only 0 dims for '{{node strided_slice_5}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=9, ellipsis_mask=0, end_mask=9, new_axis_mask=6, shrink_axis_mask=0](Cast_2, strided_slice_5/stack, strided_slice_5/stack_1, strided_slice_5/stack_2)' with input shapes: [], [4], [4], [4] and with computed input tensors: input[3] = <1 1 1 1>.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#　葡萄牙語做為輸入語言，英語作為目標語言\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 50 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "                epoch + 1, batch, train_loss.result(), train_accuracy.result()\n",
    "            ))\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                            ckpt_save_path))\n",
    "\n",
    "    print('Epoch {} Loss {:.4f} Accuracy {:.4f} '.format(\n",
    "        epoch+1, train_loss.result(), train_accuracy.result()\n",
    "    ))\n",
    "\n",
    "    print('Time taken for 1 epoch: {} secs \\n'.format(time.time()-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
