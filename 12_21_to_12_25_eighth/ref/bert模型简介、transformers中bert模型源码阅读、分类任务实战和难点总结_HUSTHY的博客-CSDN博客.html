<!DOCTYPE html>
<!-- saved from url=(0054)https://blog.csdn.net/HUSTHY/article/details/105882989 -->
<html lang="zh-CN"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <style>.login-box{position: fixed;display: none;left: 50%;top: 50%;z-index: 10000;-webkit-transform: translate(-50%, -50%);-ms-transform: translate(-50%, -50%);-o-transform: translate(-50%, -50%);-moz-transform: translate(-50%, -50%);transform: translate(-50%, -50%);background-color: #fff;}.login-mark{position: fixed;top: 0;left: 0;z-index: 9999;background-color: rgba(0, 0, 0, 0.5);width: 100%;height: 100%;display: none;}</style>
    <link rel="canonical" href="https://blog.csdn.net/HUSTHY/article/details/105882989">
    
    <meta name="renderer" content="webkit">
    <meta name="force-rendering" content="webkit">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="report" content="{&quot;pid&quot;: &quot;blog&quot;, &quot;spm&quot;:&quot;1001.2101&quot;}">
    <meta name="referrer" content="always">
    <meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" media="handheld" href="https://blog.csdn.net/HUSTHY/article/details/105882989#">
    <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848">
    <meta name="applicable-device" content="pc">
    <link href="https://g.csdnimg.cn/static/logo/favicon32.ico" rel="shortcut icon" type="image/x-icon">
    <title>bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客</title>
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/osd.js.下載"></script><script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/f(4).txt"></script><script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/f(5).txt" id="google_shimpl"></script><script type="text/javascript" async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/auto_dup"></script><script type="text/javascript" async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/saved_resource"></script><script type="text/javascript" charset="utf-8" async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/apiaccept"></script><script type="text/javascript" async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/trackad.js.下載"></script><script type="text/javascript" async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/bchm"></script><script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/push.js.下載"></script><script type="text/javascript" async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/saved_resource(1)"></script><script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/hm.js.下載"></script><script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/push.js(1).下載" id="ttzz"></script><script>
      (function(){ 
        var el = document.createElement("script"); 
        el.src = "https://s3a.pstatp.com/toutiao/push.js?1abfa13dfe74d72d41d83c86d240de427e7cac50c51ead53b2e79d40c7952a23ed7716d05b4a0f683a653eab3e214672511de2457e74e99286eb2c33f4428830"; 
        el.id = "ttzz"; 
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(el, s);
      })(window)
    </script>
        <meta name="keywords" content="bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结">
        <meta name="csdn-baidu-search" content="{&quot;autorun&quot;:true,&quot;install&quot;:true,&quot;keyword&quot;:&quot;bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结&quot;}">
    <meta name="description" content="1、bert模型简介和原理回顾2、bert模型源码理解3、bert模型任务实战4、bert模型一些难点">
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/blog.js.下載" type="text/javascript"></script>
        <link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/detail_enter-7eae656c78.min.css">
    <script type="application/ld+json">{"@context":"https://ziyuan.baidu.com/contexts/cambrian.jsonld","@id":"https://blog.csdn.net/HUSTHY/article/details/105882989","appid":"1638831770136827","pubDate":"2020-05-09T23:59:05","title":"bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客","upDate":"2020-05-09T23:59:05"}</script>
        <link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/skin3-template-45808e735f.min.css">
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/jquery-1.9.1.min.js.下載" type="text/javascript"></script>
    <script type="text/javascript">
        var isCorporate = false;//注释删除enterprise
        var username =  "HUSTHY";
        var skinImg = "white";
        var blog_address = "https://blog.csdn.net/HUSTHY";
        var currentUserName = "";
        var isOwner = false;
        var loginUrl = "http://passport.csdn.net/account/login?from=https://blog.csdn.net/HUSTHY/article/details/105882989";
        var blogUrl = "https://blog.csdn.net/";
        var avatar = "https://profile.csdnimg.cn/0/7/2/3_husthy";
        var articleTitle = "bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结";
        var articleDesc = "1、bert模型简介和原理回顾2、bert模型源码理解3、bert模型任务实战4、bert模型一些难点";
        var articleTitles = "bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客";
        var nickName = "colourmind";
        var articleDetailUrl = "https://blog.csdn.net/HUSTHY/article/details/105882989";
        if(window.location.host.split('.').length == 3) {
            blog_address = blogUrl + username;
        }
        var skinStatus = "White";
        var blogStaticHost = "https://csdnimg.cn/release/blogv2/"
    </script>
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/saved_resource(2)" type="text/javascript"></script>
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/report.js.下載" type="text/javascript"></script>
    <link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/sandalstrap.min.css">
    <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/ds.js.下載"></script>
<link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/csdn-toolbar-default.css"><script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/baidu_opensug-1.0.1.js.下載"></script><link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/collection-box.css"><script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/user-login.js.下載"></script><link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/user-tooltip.css"><link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/user-medal.css"><style type="text/css">pre{position: relative}pre:hover .hljs-button{display: block}.hljs-button{display: none;position: absolute;right: 4px;top: 4px;font-size: 12px;color: #4d4d4d;background-color: white;padding: 2px 8px;margin: 8px;border-radius: 4px;cursor: pointer; box-shadow: 0 2px 4px rgba(0,0,0,0.05), 0 2px 4px rgba(0,0,0,0.05);}.hljs-button:after{content: attr(data-title)}code .hljs-button{margin: 2px 8px;}</style><style type="text/css">.hljs-ln{border-collapse:collapse}            .hljs-ln td{padding:0}            .hljs-ln-n{text-align: right;padding-right: 8px;}            .hljs-ln-n:before{content:attr(data-line-number)}</style><link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/side-toolbar.css"><link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/saved_resource(3)"><link rel="stylesheet" type="text/css" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/csdn-footer.css"><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css"></style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><meta http-equiv="origin-trial" content="A1H+PzQW00tt6dlReHFzfO4EtBaEtEImIF9ZNiF54JpDi1bO6/7PK96Q0qxy017wgzSy9ByDKoju2mo57DH+MwoAAAB7eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiVHJ1c3RUb2tlbnMiLCJleHBpcnkiOjE2MTAzOTg0NTIsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A1H+PzQW00tt6dlReHFzfO4EtBaEtEImIF9ZNiF54JpDi1bO6/7PK96Q0qxy017wgzSy9ByDKoju2mo57DH+MwoAAAB7eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiVHJ1c3RUb2tlbnMiLCJleHBpcnkiOjE2MTAzOTg0NTIsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><link rel="preload" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/f(6).txt" as="script"><script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/f(6).txt"></script></head>
<body class="nodata " style=""><div id="BAIDU_DUP_fp_wrapper" style="position: absolute; left: -1px; bottom: -1px; z-index: 0; width: 0px; height: 0px; overflow: hidden; visibility: hidden; display: none;"><iframe id="BAIDU_DUP_fp_iframe" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/o.html" style="width: 0px; height: 0px; visibility: hidden; display: none;"></iframe></div><div id="MathJax_Message" style="display: none;"></div><div id="csdn-toolbar" style="position: fixed; top: 0px; left: 0px; z-index: 9999; width: 100%;">
                    <div class="toolbar-inside">
                      <div class="toolbar-container">
                        <div class="toolbar-container-left">
                          <div class="toolbar-logo toolbar-subMenu-box csdn-toolbar-fl"><a data-report-click="{&quot;spm&quot;:&quot;3001.4476&quot;}" data-report-query="spm=3001.4476" href="https://www.csdn.net/"><img title="CSDN首页" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201124032511.png"></a>
                    <div class="toolbar-subMenu">
                    <img width="96" height="96" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201120101655.png">
                  </div></div>
                          <ul class="toolbar-menus csdn-toolbar-fl" style="width: auto;"><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://www.csdn.net/&quot;,&quot;spm&quot;:&quot;3001.5359&quot;}" data-report-query="spm=3001.5359" href="https://www.csdn.net/">
                                  首页
                                  
                                </a>
                                
                              </li><li class="active ">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/&quot;,&quot;spm&quot;:&quot;3001.4477&quot;}" data-report-query="spm=3001.4477" href="https://blog.csdn.net/">
                                  博客
                                  
                                </a>
                                
                              </li><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/&quot;,&quot;spm&quot;:&quot;3001.4482&quot;}" data-report-query="spm=3001.4482" href="https://edu.csdn.net/">
                                  程序员学院
                                  
                                </a>
                                
                              </li><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/&quot;,&quot;spm&quot;:&quot;3001.4483&quot;}" data-report-query="spm=3001.4483" href="https://download.csdn.net/">
                                  下载
                                  
                                </a>
                                
                              </li><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://bbs.csdn.net/&quot;,&quot;spm&quot;:&quot;3001.4491&quot;}" data-report-query="spm=3001.4491" href="https://bbs.csdn.net/">
                                  论坛
                                  
                                </a>
                                
                              </li><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://ask.csdn.net/&quot;,&quot;spm&quot;:&quot;3001.4492&quot;}" data-report-query="spm=3001.4492" href="https://ask.csdn.net/">
                                  问答
                                  
                                </a>
                                
                              </li><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://codechina.csdn.net/?utm_source=csdn_toolbar&quot;,&quot;spm&quot;:&quot;3001.4493&quot;}" data-report-query="spm=3001.4493" href="https://codechina.csdn.net/?utm_source=csdn_toolbar">
                                  代码
                                  
                                </a>
                                
                              </li><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://codechina.csdn.net/?utm_source=csdn_toolbar&quot;,&quot;spm&quot;:&quot;3001.5342&quot;}" data-report-query="spm=3001.5342" href="https://live.csdn.net/?utm_source=csdn_toolbar">
                                  直播
                                  
                                </a>
                                
                              </li><li class="">
                                <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://book.csdn.net/&quot;,&quot;spm&quot;:&quot;3001.4495&quot;}" data-report-query="spm=3001.4495" href="https://book.csdn.net/">
                                  电子书
                                  
                                </a>
                                
                              </li></ul>
                        </div>
                        <div class="toolbar-container-middle">
                          <div class="toolbar-search onlySearch"><div class="toolbar-search-container">
                    <input id="toolbar-search-input" autocomplete="off" type="text" value="" placeholder="python爬取京东手机评论">
                    <button id="toolbar-search-button"></button>
                    <input type="password" autocomplete="new-password" readonly="" disabled="true" style="display: none; position:absolute;left:-9999999px;width:0;height:0;">
                  </div></div>
                        </div>
                        <div class="toolbar-container-right">
                          <div class="toolbar-btns onlyUser"><div class="toolbar-btn toolbar-btn-login csdn-toolbar-fl ">
                       <a data-report-click="{&quot;spm&quot;:&quot;3001.5105&quot;}" data-report-query="spm=3001.5105" href="https://passport.csdn.net/account/login">登录/注册</a>
                      </div>
                    <div class="toolbar-btn toolbar-btn-vip csdn-toolbar-fl">
                      <a data-report-click="{&quot;mod&quot;:&quot;popu_336&quot;,&quot;dest&quot;:&quot;https://mall.csdn.net/vip&quot;,&quot;spm&quot;:&quot;3001.4496&quot;}" data-report-query="spm=3001.4496" href="https://mall.csdn.net/vip">会员中心 </a>
                    </div>
                    <div class="toolbar-btn toolbar-btn-collect csdn-toolbar-fl">
                      <a data-report-click="{&quot;spm&quot;:&quot;3001.4506&quot;}" data-report-query="spm=3001.4506" href="https://i.csdn.net/#/uc/collection-list?type=1">收藏</a>
                    </div>
                    
                    <div class="toolbar-btn toolbar-btn-msg csdn-toolbar-fl">
                      <div class="toolbar-subMenu-box">
                        <a data-report-click="{&quot;spm&quot;:&quot;3001.4508&quot;}" data-report-query="spm=3001.4508" id="toolbar-remind" href="https://live.csdn.net/room/py_ai_326/9MUeZ9A7?utm_source=gonggao_1201">消息</a>
                      <div class="toolbar-subMenu">
                    <a id="toolbar-announcement" href="https://live.csdn.net/room/py_ai_326/9MUeZ9A7?utm_source=gonggao_1201">公告</a>
                         
                  </div></div>
                      <div class="toolbar-msg-box"></div>
                    </div>
                    <div class="toolbar-btn toolbar-btn-write csdn-toolbar-fl ">
                      <a data-report-click="{&quot;spm&quot;:&quot;3001.4503&quot;}" data-report-query="spm=3001.4503" href="https://mp.csdn.net/"><i></i>创作中心</a>
                    
        <div id="csdn-toolbar-write" class="csdn-toolbar-plugin" style="display: none;">
          <div class="csdn-toolbar-plugin-triangle"></div>
          <ul class="csdn-toolbar-write-box">
            <li class="csdn-toolbar-write-box-blog">
              <a href="https://mp.csdn.net/editor/html" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.5352&quot;}" data-report-query="spm=3001.5352">
                <i class="csdn-toolbar-write-icon"></i>
                <span>写文章</span>
              </a>
            </li>
            <li class="csdn-toolbar-write-box-blink">
              <a href="https://blink.csdn.net/" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.5353&quot;}" data-report-query="spm=3001.5353">
                <i class="csdn-toolbar-write-icon"></i>
                <span>发Blink</span>
              </a>
            </li>
            <li class="csdn-toolbar-write-box-ask">
              <a href="https://ask.csdn.net/" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.5354&quot;}" data-report-query="spm=3001.5354">
                <i class="csdn-toolbar-write-icon"></i>
                <span>提问题</span>
              </a>
            </li>
            <li class="csdn-toolbar-write-box-upload">
              <a href="https://mp.csdn.net/console/uploadResources" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.5355&quot;}" data-report-query="spm=3001.5355">
                <i class="csdn-toolbar-write-icon"></i>
                <span>传资源</span>
              </a>
            </li>
            <li class="csdn-toolbar-write-box-code">
              <a href="https://codechina.csdn.net/explore" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.5356&quot;}" data-report-query="spm=3001.5356">
                <i class="csdn-toolbar-write-icon"></i>
                <span>建项目</span>
              </a>
            </li>
          </ul>
        
        <div class="csdn-toolbar-write-activity">
          <div class="csdn-toolbar-write-activity-head">创作活动</div>
          <ul>
          <li>
            <a href="https://marketing.csdn.net/p/2eb579df2a34226edce6b2e84c396de2" target="_blank">#2020年【年度征文】，与CSDN赴一场无话不说的约！</a>
          </li>
        
          <li>
            <a href="https://marketing.csdn.net/p/31b55279869557f609c69c4a4445f55b" target="_blank">#腾讯位置服务开发应用征文大赛</a>
          </li>
        </ul>
          <div class="toolbar-write-activity-more">
            <a href="https://mp.csdn.net/console/creative" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.5358&quot;}" data-report-query="spm=3001.5358">查看更多<i></i></a>
          </div>
        </div>
      </div>
      </div></div>
                        </div>
                      </div>
                    </div>
                  </div>
        <script>
            var toolbarSearchExt = '{"landingWord":[],"queryWord":"","tag":[],"title":"bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结"}';
        </script>
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/csdn-toolbar.js.下載" type="text/javascript"></script>
    <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
    </script>
<link rel="stylesheet" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/blog_code-01256533b5.min.css">
<link rel="stylesheet" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/chart-3456820cac.css">
<div class="main_father clearfix d-flex justify-content-center" style="height: auto !important;"> 
    <div class="container clearfix" id="mainBox" style="height: auto !important;">
        <main>
<script type="text/javascript">
    var blogSensitiveWords = "";
    function getQueryString(name) {   
      var reg = new RegExp("(^|&)" + name + "=([^&]*)(&|$)"); //构造一个含有目标参数的正则表达式对象  
      var r = window.location.search.substr(1).match(reg);  //匹配目标参数
      if( r != null ) return decodeURIComponent( r[2] ); return '';   
    }
    function stripscript(s){ 
      var pattern = new RegExp("[`~!@#$^&*()=|{}':;',\\[\\].<>/?~！@#￥……&*（）——|{}【】‘；：”“'。，、？%]") 
      var rs = ""; 
      for (var i = 0; i < s.length; i++) { 
        rs = rs+s.substr(i, 1).replace(pattern, ''); 
      } 
      return rs; 
    }
    var blogHotWords = stripscript(getQueryString('utm_term')).length > 1 ? stripscript(getQueryString('utm_term')) : ''
</script>
<div class="blog-content-box">
    <div class="article-header-box">
        <div class="article-header">
            <div class="article-title-box">
                <h1 class="title-article" id="articleContentId">bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结</h1>
            </div>
            <div class="article-info-box">
                <div class="article-bar-top">
                    <img class="article-type-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/original.png" alt="">
                    <div class="bar-content">
                    <a class="follow-nickName " href="https://blog.csdn.net/HUSTHY" target="_blank" rel="noopener">colourmind</a>
                    <span class="time">2020-05-09 23:59:05</span>
                    <img class="article-read-img article-heard-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/articleReadEyes.png" alt="">
                    <span class="read-count">2439</span>
                    <a id="blog_detail_zk_collection" class="un-collection" data-report-click="{&quot;mod&quot;:&quot;popu_823&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4232&quot;,&quot;ab&quot;:&quot;new&quot;}">
                        <img class="article-collect-img article-heard-img un-collect-status isdefault" style="display:inline-block" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarCollect.png" alt="">
                        <img class="article-collect-img article-heard-img collect-status isactive" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarCollectionActive.png" alt="">
                        <span class="name">收藏</span>
                        <span class="get-collection">
                            27
                        </span>
                    </a>
                    </div>
                </div>
                <div class="blog-tags-box">
                    <div class="tags-box artic-tag-box">
                            <span class="label">分类专栏：</span>
                                <a class="tag-link" href="https://blog.csdn.net/husthy/category_9330450.html" target="_blank" rel="noopener">NLP自然语言处理</a>
                                <a class="tag-link" href="https://blog.csdn.net/husthy/category_9653010.html" target="_blank" rel="noopener">pytorch</a>
                    </div>
                </div>
                <div class="up-time"><span>最后发布:2020-05-09 23:59:05</span><span>首次发布:2020-05-09 23:59:05</span></div>
                <div class="slide-content-box">
                    <div class="article-copyright">
                        <div class="creativecommons">
                            版权声明：本文为博主原创文章，遵循<a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。
                        </div>
                        <div class="article-source-link">
                            本文链接：<a href="https://blog.csdn.net/HUSTHY/article/details/105882989" target="_blank">https://blog.csdn.net/HUSTHY/article/details/105882989</a>
                        </div>
                    </div>
                </div>
                <div class="operating">
                    <a class="href-article-edit slide-toggle">版权</a>
                </div>
            </div>
        </div>
    </div>
    <article class="baidu_pl">
        <div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/ck_htmledit_views-b5506197d8.css">
                <div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="" style="margin-left:0px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t0" target="_self">一、bert模型简介</a></p> 
<p id="" style="margin-left:40px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t1" target="_self">bert与训练的流程：</a></p> 
<p id="" style="margin-left:40px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t2" target="_self">bert模型的输入</a></p> 
<p id="" style="margin-left:0px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t3" target="_self">二、huggingface的bert源码浅析</a></p> 
<p id="" style="margin-left:40px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t4" target="_self">bert提取文本词向量</a></p> 
<p id="" style="margin-left:40px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t5" target="_self">BertModel代码阅读</a></p> 
<p id="" style="margin-left:40px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t6" target="_self">BertEmbedding子模型</a></p> 
<p id="" style="margin-left:40px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t7" target="_self">BertEncoder</a></p> 
<p id="" style="margin-left:80px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t8" target="_self">BertAttention</a></p> 
<p id="" style="margin-left:80px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t9" target="_self">BertIntermediate</a></p> 
<p id="" style="margin-left:80px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t10" target="_self">BertOutput(config)</a></p> 
<p id="" style="margin-left:40px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t11" target="_self">BertPooler()</a></p> 
<p id="" style="margin-left:0px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t12" target="_self">三、Bert文本分类任务实战</a></p> 
<p id="" style="margin-left:0px;"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t13" target="_self">四、Bert模型难点总结</a></p> 
<p style="margin-left:0px;">写在最前面，这篇博客篇幅有点长，原因是贴的代码和图有点多，感兴趣的可以坚持读下去！</p> 
<hr>
<h1 id="%E4%B8%80%E3%80%81bert%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B"><a name="t0"></a><a name="t0"></a>一、bert模型简介</h1> 
<p>&nbsp; &nbsp; &nbsp; &nbsp; 2018年bert模型被谷歌提出，它在NLP的11项任务中取得了state of the art 的结果。bert模型是由很多层transformer结构堆叠而成，这里简单看看一下transformer的结构，上一张经典的图片，如下：</p> 
<p><img alt="" height="408" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/2020050415233287.png" width="553"></p> 
<p>可以看到transformer是由encoder和decoder模块构成，而bert模型则是利用了transformer的encoder模块。最轻量的bert买模型是由12层transformer，12头注意力，768维的hidden state，在论文中的结构简图如下：</p> 
<p><img alt="" height="144" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200504153004586.png" width="554"></p> 
<p>这样的双向transformer的结构，在NLP的大部分任务中取得了很好的效果，具备较强的泛化能力。由于使用了海量的语料进行了训练，bert模型可以使用pretrain——fine-tune这种方式来进行各类NLP任务。</p> 
<h2 id="1.1%E3%80%81bert%E4%B8%8E%E8%AE%AD%E7%BB%83%E7%9A%84%E6%B5%81%E7%A8%8B%EF%BC%9A"><a name="t1"></a><a name="t1"></a>bert与训练的流程：</h2> 
<p>这个过程包括两个任务，一个是Masked Language Model(遮掩语言模型)，另外一个是Next Sentence Prediction(下一句预测)。</p> 
<p>Masked Language Model(遮掩语言模型)可以理解为是做完型填空，把语料中15%的词遮掩掉，来学习词和词之间的一些规律；</p> 
<p>Next Sentence Prediction就是学习语料中上下文中2个句子之间的关系规律。</p> 
<p>通过这2个阶段任务的学习，bert就会把文本的语法和语义信息学习到。bert模型中的self-attention机制可以使用文本其他的词来增强目标词的语义表示，这也是bert模型吊打其他模型的一个关键原因。</p> 
<h2 id="1.2%E3%80%81bert%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BE%93%E5%85%A5"><a name="t2"></a><a name="t2"></a>bert模型的输入</h2> 
<p>bert模型的输入可以是一个句子或者句子对，代码层面来说，就是输入了句子或者句子对对应的3个向量。它们分别是token embedding，segment embedding和position embedding，具体的含义：</p> 
<p>token embedding：句子的词向量</p> 
<p>segment embedding：是那个句子的0和1</p> 
<p>position embedding：位置向量，指明每个字在句中的位置。</p> 
<p>关于position embedding这里有两种求法，一种是有相应的三角函数公式得出的，这种是绝对向量；还有一种是学习得到的，这种是相对向量。具体形式如下：</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200504155029651.png"></p> 
<h1 id="%E4%BA%8C%E3%80%81huggingface%E7%9A%84bert%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90"><a name="t3"></a><a name="t3"></a>二、<u><span style="color:#0000ff;"><u>huggingface</u></span></u>的bert源码浅析</h1> 
<p>关于bert模型的使用，我主要是使用<u><span style="color:#0000ff;"><u>huggingface</u></span></u>的transformer库来调用bert和使用——一般是直接用来bert来获取词向量。这里就bert的使用和<u><span style="color:#0000ff;"><u>huggingface</u></span></u>中的源码进行一些解读。</p> 
<h2 id="bert%E6%8F%90%E5%8F%96%E6%96%87%E6%9C%AC%E8%AF%8D%E5%90%91%E9%87%8F"><a name="t4"></a><a name="t4"></a>bert提取文本词向量</h2> 
<p>首先看一段简单的代码，使用huggingface的transformers(其实就是实现的bert)来提取句——我爱武汉！我爱中国！——的向量。代码如下：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:1196px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel,BertTokenizer,BertConfig</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">config = BertConfig.from_pretrained(<span class="hljs-string">'pretrain_model/chinese-bert-wwm'</span>)<span class="hljs-comment">#第一步加载模型配置文件</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">bertmodel = BertModel.from_pretrained(<span class="hljs-string">'pretrain_model/chinese-bert-wwm'</span>,config=config)<span class="hljs-comment">#第二步初始化模型，并加载权重</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># print('***************************bertmodel***************************')</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">'pretrain_model/chinese-bert-wwm'</span>)<span class="hljs-comment">#第三步加载tokenizer</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">text1 = <span class="hljs-string">'我爱武汉！我爱中国！'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tokeniz_text1 = tokenizer.tokenize(text1)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># print(tokeniz_text1)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># print('tokeniz_text1:',len(tokeniz_text1))</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">indexed_tokens_1 = tokenizer.convert_tokens_to_ids(tokeniz_text1)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">'len(indexed_tokens_1):'</span>,len(indexed_tokens_1))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(indexed_tokens_1)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">input_ids_1 = indexed_tokens_1</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># print(indexed_tokens_1)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># print('indexed_tokens_1:',len(indexed_tokens_1))</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">segments_ids_1 = [<span class="hljs-number">0</span>]*len(input_ids_1)<span class="hljs-comment">#其实这个输入可以不用的，因为是单句的原因</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">input_masks_1 = [<span class="hljs-number">1</span>]*len(input_ids_1)<span class="hljs-comment">#其实这个输入可以不用的，因为是单句的原因</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">input_ids_1_tensor = torch.tensor([input_ids_1])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vector1,pooler1 = bertmodel(input_ids_1_tensor)<span class="hljs-comment">#应该是输入3个向量的，但是单句情况下，它自会自己做判断，然后自动生成对应的segments_ids和input_masks向量</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#这里的输出最后一层的last_hidden_state和最后一层首个token的hidden-state</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">text2 = <span class="hljs-string">'[CLS]我爱武汉！我爱中国![SEP]'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tokeniz_text2 = tokenizer.tokenize(text2)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">indexed_tokens_2 = tokenizer.convert_tokens_to_ids(tokeniz_text2)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">input_ids_2 = indexed_tokens_2</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">segments_ids_2 = [<span class="hljs-number">0</span>]*len(input_ids_2)<span class="hljs-comment">#其实这个输入可以不用的，因为是单句的原因</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">input_masks_2 = [<span class="hljs-number">1</span>]*len(input_ids_2)<span class="hljs-comment">#其实这个输入可以不用的，因为是单句的原因</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">input_ids_2_tensor = torch.tensor([input_ids_2])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vector2,pooler2 = bertmodel(input_ids_2_tensor)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">'pooler2:'</span>,pooler2)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">'vector2[:,0:1,:]:'</span>,vector2[:,<span class="hljs-number">0</span>:<span class="hljs-number">1</span>,:])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">text1_encode = tokenizer.encode(text1,add_special_tokens=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">'len(text1_encode):'</span>,len(text1_encode))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">'text1_encode:'</span>,text1_encode)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#这里的text1_encode和indexed_tokens_2是一模一样的，encode()函数会自动为文本添加特殊字符[UNK][CLS][SEP][MASK]等</span></div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>以上代码是基于pytorch来实现的，同时应用到了transoformers库！可以看到bert模型的使用非常简单！</p> 
<p>第一步，初始化bert模型和加载权重。这个步骤中，首先加载配置文件、然后加载bert模型和载入权重。</p> 
<p>第二步，对输入文本做词表映射，形成初始词向量。</p> 
<p>第三步，输入喂入bert模型中得到输入文本的结果向量。</p> 
<p>文中是bert模型的输入我这里只给出了一个那就是input_ids,另外的2个没有给出。这里的原因就是这里是单个句子，模型内部可以对另外2个输入做自动添加的处理——并不是没有，这点要注意到。</p> 
<p>这里有个疑问因为bert的输入文本得添加一个[cls]特殊字符，我认为最后的输出lsat_hidden_state中的lsat_hidden_state[:,0:1,:]应该和pooler结果是一样的，可是这里是不一样的，有点理解的偏差，不知道为什么。</p> 
<h2 id="BertModel%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB"><a name="t5"></a><a name="t5"></a>BertModel代码阅读</h2> 
<p>通过上文中的代码，大致可以知道怎么调用一些API来创建bert模型和应用它。那么<u><span style="color:#0000ff;"><u>huggingface</u></span></u>中是怎么实现BertModel的这个也是比较重要的，这里我们就好好阅读以下其中关于BertModel实现的代码。看一张transformers项目文件结构图：</p> 
<p><img alt="" height="995" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200505231413150.png" width="460"></p> 
<p>这么面封装了很多模型的构建，我们主要是阅读modeling_bert.py文件，它在里面详细的展示了如何构建一个Bert模型的：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln hundred" style="width:1024px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertModel</span>(<span class="hljs-params">BertPreTrainedModel</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    .......</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.config = config</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.embeddings = BertEmbeddings(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.encoder = BertEncoder(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.pooler = BertPooler(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.init_weights()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_input_embeddings</span>(<span class="hljs-params">self</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> self.embeddings.word_embeddings</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">set_input_embeddings</span>(<span class="hljs-params">self, value</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.embeddings.word_embeddings = value</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_prune_heads</span>(<span class="hljs-params">self, heads_to_prune</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string"><span class="hljs-string">""" Prunes heads of the model.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">            See base class PreTrainedModel</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> layer, heads <span class="hljs-keyword">in</span> heads_to_prune.items():</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            self.encoder.layer[layer].attention.prune_heads(heads)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-meta">    @add_start_docstrings_to_callable(BERT_INPUTS_DOCSTRING)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params"><span class="hljs-params"></span></span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        self,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        input_ids=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        attention_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        token_type_ids=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        position_ids=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        head_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        inputs_embeds=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        encoder_hidden_states=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        encoder_attention_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">    </span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string"><span class="hljs-string">r""".......</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"You cannot specify both input_ids and inputs_embeds at the same time"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_shape = input_ids.size()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_shape = inputs_embeds.size()[:<span class="hljs-number">-1</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"You have to specify either input_ids or inputs_embeds"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        device = input_ids.device <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> inputs_embeds.device</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask = torch.ones(input_shape, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> token_type_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># ourselves in which case we just need to make it broadcastable to all heads.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask, input_shape, self.device</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># If a 2D ou 3D attention mask is provided for the cross-attention</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> self.config.is_decoder <span class="hljs-keyword">and</span> encoder_hidden_states <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> encoder_attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="77"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_extended_attention_mask = <span class="hljs-literal">None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="78"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="79"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Prepare head mask if needed</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="80"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 1.0 in head_mask indicate we keep the head</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="81"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># attention_probs has shape bsz x n_heads x N x N</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="82"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="83"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="84"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="85"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="86"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        embedding_output = self.embeddings(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="87"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="88"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="89"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        encoder_outputs = self.encoder(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="90"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            embedding_output,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="91"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask=extended_attention_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="92"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            head_mask=head_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="93"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_hidden_states=encoder_hidden_states,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="94"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_attention_mask=encoder_extended_attention_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="95"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="96"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        sequence_output = encoder_outputs[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="97"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pooled_output = self.pooler(sequence_output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="98"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="99"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = (sequence_output, pooled_output,) + encoder_outputs[</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="100"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-number">1</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="101"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        ]  <span class="hljs-comment"># add hidden_states and attentions if they are here</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="102"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> outputs  <span class="hljs-comment"># sequence_output, pooled_output, (hidden_states), (attentions)</span></div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>以上就是BertModel的全部代码，可以看到在BertModel类中，首先__init__()函数中定义了模型的基本模块，然后在forward()函数里面使用这些结构模块具体实现了Bert的逻辑。</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.config = config</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.embeddings = BertEmbeddings(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.encoder = BertEncoder(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.pooler = BertPooler(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.init_weights()</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>__init__()函数中定义的模型模块主要是3个，分别是BertEmbedding、BertEncoder和BertPooler。然后在forward()，输入顺序的经过这3个模块的处理就得到了我们要的结果——对应文本的bert向量。</p> 
<p>下面来阅读forward()：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:1050px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"You cannot specify both input_ids and inputs_embeds at the same time"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_shape = input_ids.size()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_shape = inputs_embeds.size()[:<span class="hljs-number">-1</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">"You have to specify either input_ids or inputs_embeds"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        device = input_ids.device <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> inputs_embeds.device</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask = torch.ones(input_shape, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> token_type_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># ourselves in which case we just need to make it broadcastable to all heads.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> attention_mask.dim() == <span class="hljs-number">3</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            extended_attention_mask = attention_mask[:, <span class="hljs-literal">None</span>, :, :]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> attention_mask.dim() == <span class="hljs-number">2</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># Provided a padding mask of dimensions [batch_size, seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># - if the model is a decoder, apply a causal mask in addition to the padding mask</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> self.config.is_decoder:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                batch_size, seq_length = input_shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                seq_ids = torch.arange(seq_length, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                causal_mask = seq_ids[<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, :].repeat(batch_size, seq_length, <span class="hljs-number">1</span>) &lt;= seq_ids[<span class="hljs-literal">None</span>, :, <span class="hljs-literal">None</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                causal_mask = causal_mask.to(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    attention_mask.dtype</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                )  <span class="hljs-comment"># causal and attention masks must have same type with pytorch version &lt; 1.3</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                extended_attention_mask = causal_mask[:, <span class="hljs-literal">None</span>, :, :] * attention_mask[:, <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, :]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                extended_attention_mask = attention_mask[:, <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, :]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">raise</span> ValueError(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-string">"Wrong shape for input_ids (shape {}) or attention_mask (shape {})"</span>.format(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    input_shape, attention_mask.shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Since attention_mask is 1.0 for positions we want to attend and 0.0 for</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># masked positions, this operation will create a tensor which is 0.0 for</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># positions we want to attend and -10000.0 for masked positions.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Since we are adding it to the raw scores before the softmax, this is</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># effectively the same as removing these entirely.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  <span class="hljs-comment"># fp16 compatibility</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        extended_attention_mask = (<span class="hljs-number">1.0</span> - extended_attention_mask) * <span class="hljs-number">-10000.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># If a 2D ou 3D attention mask is provided for the cross-attention</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> self.config.is_decoder <span class="hljs-keyword">and</span> encoder_hidden_states <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> encoder_attention_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> encoder_attention_mask.dim() == <span class="hljs-number">3</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                encoder_extended_attention_mask = encoder_attention_mask[:, <span class="hljs-literal">None</span>, :, :]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">elif</span> encoder_attention_mask.dim() == <span class="hljs-number">2</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                encoder_extended_attention_mask = encoder_attention_mask[:, <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, :]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-keyword">raise</span> ValueError(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    <span class="hljs-string">"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})"</span>.format(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                        encoder_hidden_shape, encoder_attention_mask.shape</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_extended_attention_mask = encoder_extended_attention_mask.to(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                dtype=next(self.parameters()).dtype</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            )  <span class="hljs-comment"># fp16 compatibility</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_extended_attention_mask = (<span class="hljs-number">1.0</span> - encoder_extended_attention_mask) * <span class="hljs-number">-10000.0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_extended_attention_mask = <span class="hljs-literal">None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Prepare head mask if needed</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="77"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 1.0 in head_mask indicate we keep the head</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="78"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># attention_probs has shape bsz x n_heads x N x N</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="79"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="80"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="81"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> head_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="82"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> head_mask.dim() == <span class="hljs-number">1</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="83"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                head_mask = head_mask.unsqueeze(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">-1</span>).unsqueeze(<span class="hljs-number">-1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="84"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                head_mask = head_mask.expand(self.config.num_hidden_layers, <span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="85"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">elif</span> head_mask.dim() == <span class="hljs-number">2</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="86"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                head_mask = (</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="87"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    head_mask.unsqueeze(<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">-1</span>).unsqueeze(<span class="hljs-number">-1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="88"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                )  <span class="hljs-comment"># We can specify head_mask for each layer</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="89"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            head_mask = head_mask.to(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="90"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                dtype=next(self.parameters()).dtype</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="91"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            )  <span class="hljs-comment"># switch to fload if need + fp16 compatibility</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="92"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="93"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            head_mask = [<span class="hljs-literal">None</span>] * self.config.num_hidden_layers</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>以上是一些预处理的代码。判定input_ids的合法性，不能为空不能和inputs_embeds同时输入；接着就获取使用的设备是CPU还是GPU；判定attention_mask和token_type_ids的合法性，为None的话就新建一个；处理attention_mask得到encoder_extended_attention_mask，把它传播给所有的注意力头；最后就是判定是否启用decoder——bert模型是基于encoder的，我认为这里就不必要做这个判定，bert的encoder的结果只是传递给下一层encoder，并没有传递到decoder。</p> 
<p>下面具体看核心的部分。</p> 
<p>上面把输入做一些预处理后，使得输入都合法，然后就可以喂入模型的功能模块中。第一个就是</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:1018px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">embedding_output = self.embeddings(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<h2 id="BertEmbedding%E5%AD%90%E6%A8%A1%E5%9E%8B"><a name="t6"></a><a name="t6"></a>BertEmbedding子模型</h2> 
<p>其中的self.embeddings()就是__inti__()的BertEmbeddings(config)模块，它可以看做是一个起embedding功能作用的子模型，具体代码：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:938px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertEmbeddings</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""Construct the embeddings from word, position and token_type embeddings.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=<span class="hljs-number">0</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># any TensorFlow checkpoint file</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_shape = input_ids.size()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_shape = inputs_embeds.size()[:<span class="hljs-number">-1</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        seq_length = input_shape[<span class="hljs-number">1</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        device = input_ids.device <span class="hljs-keyword">if</span> input_ids <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> inputs_embeds.device</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> position_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            position_ids = torch.arange(seq_length, dtype=torch.long, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            position_ids = position_ids.unsqueeze(<span class="hljs-number">0</span>).expand(input_shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> token_type_ids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> inputs_embeds <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            inputs_embeds = self.word_embeddings(input_ids)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        position_embeddings = self.position_embeddings(position_ids)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        token_type_embeddings = self.token_type_embeddings(token_type_ids)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        embeddings = inputs_embeds + position_embeddings + token_type_embeddings</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        embeddings = self.LayerNorm(embeddings)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        embeddings = self.dropout(embeddings)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> embeddings</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>它的具体作用就是：首先把我们输入的input_ids、token_type_ids和position_ids——(这里输入的是对应元素在词典中的index集合)经过torch.nn.Embedding()在各自的词典中得到词嵌入。然后把这3个向量直接做加法运算，接着做层归一化以及dropout()操作。这里为何可以直接相加是可以做一个专门的问题来讨论的，这里的归一化的作用应该就是避免一些数值问题、梯度问题和模型收敛问题以及分布改变问题，dropout操作随机丢弃掉一部分特征，可以增加模型的泛化性能。</p> 
<h2 id="BertEncoder"><a name="t7"></a><a name="t7"></a>BertEncoder</h2> 
<p>经过上述的处理后，我们就得到了一个维度是[batch_size,sequence_length,hidden_states]的向量embeddings。然后再把这个embeddings输入到Encoder中，代码如下，参数都很清晰明确：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">encoder_outputs = self.encoder(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            embedding_output,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask=extended_attention_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            head_mask=head_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_hidden_states=encoder_hidden_states,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            encoder_attention_mask=encoder_extended_attention_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>这里的self.encoder同样是__init__()中的BertEncoder(config)模型，全部代码如下：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:922px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertEncoder</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.output_attentions = config.output_attentions</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.output_hidden_states = config.output_hidden_states</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.layer = nn.ModuleList([BertLayer(config) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(config.num_hidden_layers)])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params"><span class="hljs-params"></span></span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        self,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        hidden_states,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        attention_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        head_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        encoder_hidden_states=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        encoder_attention_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">    </span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        all_hidden_states = ()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        all_attentions = ()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> i, layer_module <span class="hljs-keyword">in</span> enumerate(self.layer):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> self.output_hidden_states:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                all_hidden_states = all_hidden_states + (hidden_states,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            layer_outputs = layer_module(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            hidden_states = layer_outputs[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> self.output_attentions:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                all_attentions = all_attentions + (layer_outputs[<span class="hljs-number">1</span>],)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Add last layer</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> self.output_hidden_states:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            all_hidden_states = all_hidden_states + (hidden_states,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = (hidden_states,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> self.output_hidden_states:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = outputs + (all_hidden_states,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> self.output_attentions:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = outputs + (all_attentions,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> outputs </div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>其中模型定义部分的核心代码如下：</p> 
<pre><code class="language-python hljs">self.layer = nn.ModuleList([BertLayer(config) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(config.num_hidden_layers)])</code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>通过这句代码和config中的参数——"num_hidden_layers": 12——可以得出BertEncoder使用12个(层)BertLayer组成的。对每一层的bertlayer在forward()中的for循环做如下操作：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:922px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> i, layer_module <span class="hljs-keyword">in</span> enumerate(self.layer):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> self.output_hidden_states:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                all_hidden_states = all_hidden_states + (hidden_states,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            layer_outputs = layer_module(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            hidden_states = layer_outputs[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> self.output_attentions:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                all_attentions = all_attentions + (layer_outputs[<span class="hljs-number">1</span>],)</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>更新hidden_states(也就是layer_outputs[0])，然后把更新后的hidden_states传入到下一层BertLayer中，同时把每一层的hidden_states和attentions(也就是layer_outputs[1])记录下来，然后作为一个整体输出。所有最后的输出里包含的有最后一层BertLayer的hidden_states和12层所有的hidden_states以及attentions。</p> 
<p>BertLayer具体又是什么样的呢？这里就需要看看具体的BertLayer的实现：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertLayer</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.attention = BertAttention(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.is_decoder = config.is_decoder</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> self.is_decoder:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            self.crossattention = BertAttention(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.intermediate = BertIntermediate(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.output = BertOutput(config)</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>可以看到BertLayer是由BertAttention()、BertIntermediate()和BertOutput()构成。它的forward()是比较简单的，没有什么奇特的操作，都是顺序的把输入经过BertAttention()、BertIntermediate()和BertOutput()这些子模型。这里主要来看看这些子模型的实现：</p> 
<h3 id="BertAttention"><a name="t8"></a><a name="t8"></a><strong>BertAttention</strong></h3> 
<p>这里它又嵌套了一层，由BertSelfAttention()和BertSelfOutput()子模型组成！</p> 
<p>这里马上就看到self-attention机制的实现了！感觉好激动！——Self-Attention则利用了Attention机制，计算每个单词与其他所有单词之间的关联(说实话理解的不是很透彻！)</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:922px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertSelfAttention</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> config.hidden_size % config.num_attention_heads != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> hasattr(config, <span class="hljs-string">"embedding_size"</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">raise</span> ValueError(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-string">"The hidden size (%d) is not a multiple of the number of attention "</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-string">"heads (%d)"</span> % (config.hidden_size, config.num_attention_heads)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.output_attentions = config.output_attentions</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.num_attention_heads = config.num_attention_heads</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.all_head_size = self.num_attention_heads * self.attention_head_size</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.query = nn.Linear(config.hidden_size, self.all_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.key = nn.Linear(config.hidden_size, self.all_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.value = nn.Linear(config.hidden_size, self.all_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transpose_for_scores</span>(<span class="hljs-params">self, x</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        new_x_shape = x.size()[:<span class="hljs-number">-1</span>] + (self.num_attention_heads, self.attention_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = x.view(*new_x_shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params"><span class="hljs-params"></span></span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        self,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        hidden_states,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        attention_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        head_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        encoder_hidden_states=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        encoder_attention_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">    </span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        mixed_query_layer = self.query(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># If this is instantiated as a cross-attention module, the keys</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># and values come from an encoder; the attention mask needs to be</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># such that the encoder's padding tokens are not attended to.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> encoder_hidden_states <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_key_layer = self.key(encoder_hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_value_layer = self.value(encoder_hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask = encoder_attention_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_key_layer = self.key(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_value_layer = self.value(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        query_layer = self.transpose_for_scores(mixed_query_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        key_layer = self.transpose_for_scores(mixed_key_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        value_layer = self.transpose_for_scores(mixed_value_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Take the dot product between "query" and "key" to get the raw attention scores.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_scores = torch.matmul(query_layer, key_layer.transpose(<span class="hljs-number">-1</span>, <span class="hljs-number">-2</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_scores = attention_scores / math.sqrt(self.attention_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># Apply the attention mask is (precomputed for all layers in BertModel forward() function)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_scores = attention_scores + attention_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Normalize the attention scores to probabilities.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_probs = nn.Softmax(dim=<span class="hljs-number">-1</span>)(attention_scores)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># This is actually dropping out entire tokens to attend to, which might</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># seem a bit unusual, but is taken from the original Transformer paper.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_probs = self.dropout(attention_probs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Mask heads if we want to</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> head_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_probs = attention_probs * head_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        context_layer = torch.matmul(attention_probs, value_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        context_layer = context_layer.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>).contiguous()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        new_context_layer_shape = context_layer.size()[:<span class="hljs-number">-2</span>] + (self.all_head_size,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        context_layer = context_layer.view(*new_context_layer_shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = (context_layer, attention_probs) <span class="hljs-keyword">if</span> self.output_attentions <span class="hljs-keyword">else</span> (context_layer,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> outputs</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>阅读代码之前先回顾一下，self-attention的公式是什么样的，公式编辑比较麻烦直接上2个图，都是来自<a href="https://zhuanlan.zhihu.com/p/47282410">Attention机制详解（二）——Self-Attention与Transformer</a>文章中：</p> 
<p>首先定义Q、K、V</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200506203114744.png"></p> 
<p>然后应用到公式中：</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200506203245156.png"></p> 
<p>以上就是单个头的self-attention的公式，多头的话就可以计算多次，然后在合并起来。这里就可以应用到矩阵运算了，还要注意的点就是Q、K、V的学习参数都是共享的——(要去验证)，代码对应的就是：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.query = nn.Linear(config.hidden_size, self.all_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.key = nn.Linear(config.hidden_size, self.all_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.value = nn.Linear(config.hidden_size, self.all_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#注意这里的nn.Linear包含的学习参数一个是权重参数weights一个是偏置参数bias</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#而且这里的query、key以及value它们的参数不一样，也就是并不共享参数</span></div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>参数都包含在nn.Linear中了，这里的self.query对应的是12个头的self-attention机制对应的Q的学习参数模型，当然query、key以及value它们的参数不一样，也就是并不共享参数。</p> 
<p>那么在forward()中是如何实现的呢？</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:890px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        mixed_query_layer = self.query(hidden_states)<span class="hljs-comment">#计算Q</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> encoder_hidden_states <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_key_layer = self.key(encoder_hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_value_layer = self.value(encoder_hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask = encoder_attention_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_key_layer = self.key(hidden_states) <span class="hljs-comment">#计算K</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            mixed_value_layer = self.value(hidden_states)<span class="hljs-comment">#计算V</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#做转置操作——这有点特殊：mixed_query_layer[batch_size,sequence_length,hidden_states]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">       <span class="hljs-comment">#query_layer的维度：[batch_size,num_attention_heads,sequence_length,attention_head_size]</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        query_layer = self.transpose_for_scores(mixed_query_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        key_layer = self.transpose_for_scores(mixed_key_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        value_layer = self.transpose_for_scores(mixed_value_layer)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#Q和K做点积</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_scores = torch.matmul(query_layer, key_layer.transpose(<span class="hljs-number">-1</span>, <span class="hljs-number">-2</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#Q和K做点积后然后除以根号下多头主力的尺寸</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_scores = attention_scores / math.sqrt(self.attention_head_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> attention_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># Apply the attention mask is (precomputed for all layers in BertModel forward() function)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_scores = attention_scores + attention_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Normalize the attention scores to probabilities.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#做softmax操作，归一化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_probs = nn.Softmax(dim=<span class="hljs-number">-1</span>)(attention_scores)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># This is actually dropping out entire tokens to attend to, which might</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># seem a bit unusual, but is taken from the original Transformer paper.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        attention_probs = self.dropout(attention_probs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># Mask heads if we want to</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> head_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_probs = attention_probs * head_mask</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#中间结果和V做点积，得到最终结果——注意力得分也就是公式中的Z</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        context_layer = torch.matmul(attention_probs, value_layer)</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>以上代码的中文注释就把计算过程分析清楚了，计算mixed_query_layer、mixed_key_layer和mixed_value_layer，然后做转置(说是维度变换更贴切一点)；接着mixed_query_layer、mixed_key_layer做点积操作，然后除以注意力头的尺寸的开方，做softmax操作；最后和mixed_value_layer相乘，得到注意力得分————矩阵计算代码就很好的实现了self-attention。</p> 
<p>以上就是完成了self-attention，然后接下来就进入BertSelfOutput():</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertSelfOutput</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dense = nn.Linear(config.hidden_size, config.hidden_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, hidden_states, input_tensor</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.dense(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.dropout(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.LayerNorm(hidden_states + input_tensor)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> hidden_states</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>以上BertSelfOutput()代码很简单，把self-attention输出的结果经过线性模型和dropout操作，最后做层归一化。到这里就跳出了BertAttention()模型，然后就进入中间层BertIntermediate()。</p> 
<h3 id="BertIntermediate"><a name="t9"></a><a name="t9"></a><strong>BertIntermediate</strong></h3> 
<p>BertIntermediate()作为中间层代码很简单：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertIntermediate</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> isinstance(config.hidden_act, str):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            self.intermediate_act_fn = ACT2FN[config.hidden_act]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            self.intermediate_act_fn = config.hidden_act</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, hidden_states</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.dense(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.intermediate_act_fn(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> hidden_states</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>经过一个全连接层，由于config.hidden_size&lt;config.intermediate_size，这里的Linear把特征空间变大了，然后进过了gelu激活函数，增加了特征的非线性性。</p> 
<h3 id="BertOutput(config)"><a name="t10"></a><a name="t10"></a><strong>BertOutput(config)</strong></h3> 
<p>跳出BertIntermediate()作为中间层后，就进入了BertOutput(config)模型，这个是BertLayer()模型的最后一个子模型。</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertOutput</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, hidden_states, input_tensor</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.dense(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.dropout(hidden_states)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        hidden_states = self.LayerNorm(hidden_states + input_tensor)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> hidden_states</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>经过线性模型和dropout操作，最后做层归一化，把特征空间又缩小回来了。最后输出一个hidden_states，这里就是一个BertLayer()的输出了。</p> 
<h2 id="BertPooler()"><a name="t11"></a><a name="t11"></a>BertPooler()</h2> 
<p>然后经历了12个BertLayer()的操作，一层一层的变换，最后得出的outputs进入BertPooler():</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">sequence_output = encoder_outputs[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">pooled_output = self.pooler(sequence_output)</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>pooler代码如下：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertPooler</span>(<span class="hljs-params">nn.Module</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dense = nn.Linear(config.hidden_size, config.hidden_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.activation = nn.Tanh()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, hidden_states</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># We "pool" the model by simply taking the hidden state corresponding</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># to the first token.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        first_token_tensor = hidden_states[:, <span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pooled_output = self.dense(first_token_tensor)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pooled_output = self.activation(pooled_output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> pooled_output</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#以上的pooler作用要具体的去调试hidden_states的shape。</span></div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>由代码可知这个pooler的功能就是把last_hidden_states的第二维的第一维也就是文本对应的第一个；。。。、。。</p> 
<p>以上差不多就是BertModel的具体实现，由于这个模型的代码嵌套调用过多，可能理解起来有一定的困惑，那么接下来就需要一个图片来可视化理解。上图：</p> 
<p><img alt="" height="1200" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200507151336225.png" width="500"></p> 
<p style="margin-left:0pt;">上图是<u><span style="color:#0000ff;"><u>huggingface</u></span></u>中的BertModel的结构流程图(简图，有很多疏漏的地方勿怪！)，bertModel的输入和基本的子模型以及数据的流向都显示出来了，对应着代码理解起来更加方便。黄色的图形就是torch中的基本函数模块(这里的Q、K和V不是)，其他颜色的矩形就是模型，平行四边形就是数据。</p> 
<p style="margin-left:0pt;">以上就是对BertModel实现代码的简单解析，里面涉及到很多的细节：不同模型模块的参数以及它们的维度信息，还有就是变量的维度变化，以及每个模型模块的具体作用和意义，没有去深究，读者有精力的话可以自己去深究。</p> 
<h1 id="%E4%B8%89%E3%80%81Bert%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98" style="margin-left:0pt;"><a name="t12"></a><a name="t12"></a>三、Bert文本分类任务实战</h1> 
<p style="margin-left:0pt;">&nbsp; &nbsp; &nbsp; &nbsp; 这里我们要写一个使用transformers项目中的分类器来实现一个简单的文本分类任务，这里我们没有自己取重写Dataloader以及模型的训练，就是直接把transformers项目中的bert分类器拿过来进行fine-tune，工作量少，结果也比较好！当然也可以完全自己实现(前面也自己实现过一个基于bert的句子分类的任务——<a href="https://blog.csdn.net/HUSTHY/article/details/103767932">使用bert模型做句子分类</a>，有兴趣的可以移步)，后续有时间的话可以写一个各个模型文本分类任务的比较博客，更加熟练文本分类的一些代码coding和知识——增加熟练度，也可以给大家分享一下。</p> 
<p>来看本文的transformers项目中的bert分类器进行fine-tune作文本分类的任务，在这个项目里面已经把全部的代码写好了，我们只需要把我们的文本处理成项目能够识别和读取的形式。简单的分析一下，分类任务的代码：</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200509105113867.png"></p> 
<p>主要的分类任务的代码是在run_glue.py文件中，这里面定义了main函数，命令行参数接收器，模型的加载和调用，模型的训练以及验证，和数据读取以及处理的功能模块调用。</p> 
<p>我们看一下这里调用的分类模型，代码是这样的：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = AutoModelForSequenceClassification.from_pretrained(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        args.model_name_or_path,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        from_tf=bool(<span class="hljs-string">".ckpt"</span> <span class="hljs-keyword">in</span> args.model_name_or_path),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        config=config,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        cache_dir=args.cache_dir,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    )</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>其实最终这里的AutoModelForSequenceClassification.from_pretrained()调用的是modeling_bert.py中的BertForSequenceClassification类，它就是具体的分类器实现：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BertForSequenceClassification</span>(<span class="hljs-params">BertPreTrainedModel</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, config</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        super().__init__(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.num_labels = config.num_labels</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.bert = BertModel(config)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.dropout = nn.Dropout(config.hidden_dropout_prob)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.init_weights()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params"><span class="hljs-params"></span></span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        self,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        input_ids=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        attention_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        token_type_ids=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        position_ids=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        head_mask=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        inputs_embeds=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        labels=None,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">    </span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = self.bert(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            input_ids,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            attention_mask=attention_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            token_type_ids=token_type_ids,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            position_ids=position_ids,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            head_mask=head_mask,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            inputs_embeds=inputs_embeds,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pooled_output = outputs[<span class="hljs-number">1</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        pooled_output = self.dropout(pooled_output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        logits = self.classifier(pooled_output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = (logits,) + outputs[<span class="hljs-number">2</span>:]  <span class="hljs-comment"># add hidden states and attention if they are here</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> labels <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> self.num_labels == <span class="hljs-number">1</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-comment">#  We are doing regression</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                loss_fct = MSELoss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                loss = loss_fct(logits.view(<span class="hljs-number">-1</span>), labels.view(<span class="hljs-number">-1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                loss_fct = CrossEntropyLoss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                loss = loss_fct(logits.view(<span class="hljs-number">-1</span>, self.num_labels), labels.view(<span class="hljs-number">-1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = (loss,) + outputs</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> outputs</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>模型调用了BertModel，然后做使用nn.Linear(config.hidden_size, self.config.num_labels)做分类，loss函数是常用的交叉熵损失函数。以上就是分类器的一些简单的分析。 我们要做的工作就是仿照项目里的代码写一个任务处理器：</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200509110157866.png"></p> 
<p>项目目录结构：transformerer_local/data/glue.py，注意这里的transformerer_local原本应该是transformerer，我这里已经做了修改。在glue.py添加上我们的分类任务代码——添加一个读取文件中的文本然后，然后把每条数据序列化成Example，注意get_labels()函数，把自己的类别数目实现过来，代码如下：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln" style="width:866px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyownProcessor</span>(<span class="hljs-params">DataProcessor</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string">"""Processor for the CoLA data set (GLUE version)."""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_example_from_tensor_dict</span>(<span class="hljs-params">self, tensor_dict</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">"""See base class."""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> InputExample(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            tensor_dict[<span class="hljs-string">"idx"</span>].numpy(),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            tensor_dict[<span class="hljs-string">"sentence"</span>].numpy().decode(<span class="hljs-string">"utf-8"</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-literal">None</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            str(tensor_dict[<span class="hljs-string">"label"</span>].numpy()),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_train_examples</span>(<span class="hljs-params">self, data_dir</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">"""See base class."""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> self._create_examples(self._read_tsv(os.path.join(data_dir, <span class="hljs-string">"train.tsv"</span>)), <span class="hljs-string">"train"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_dev_examples</span>(<span class="hljs-params">self, data_dir</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">"""See base class."""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> self._create_examples(self._read_tsv(os.path.join(data_dir, <span class="hljs-string">"dev.tsv"</span>)), <span class="hljs-string">"dev"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_predict_examples</span>(<span class="hljs-params">self, data_dir</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> self._create_examples(self._read_tsv(os.path.join(data_dir, <span class="hljs-string">"test.tsv"</span>)), <span class="hljs-string">"predict"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_labels</span>(<span class="hljs-params">self</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">"""See base class."""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> [<span class="hljs-string">"0"</span>, <span class="hljs-string">"1"</span>,<span class="hljs-string">"2"</span>,<span class="hljs-string">"3"</span>,<span class="hljs-string">"4"</span>,<span class="hljs-string">"5"</span>,<span class="hljs-string">"6"</span>,<span class="hljs-string">"7"</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_create_examples</span>(<span class="hljs-params">self, lines, set_type</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-string">"""Creates examples for the training and dev sets."""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        examples = []</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> (i, line) <span class="hljs-keyword">in</span> enumerate(lines):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            guid = <span class="hljs-string">"%s-%s"</span> % (set_type, i)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> len(line)==<span class="hljs-number">2</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                text_a = line[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                label = line[<span class="hljs-number">1</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                examples.append(InputExample(guid=guid, text_a=text_a, text_b=<span class="hljs-literal">None</span>, label=label))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                print(line)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> examples</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>同时在验证的时候，对应评价指标函数，我们这里不是binary，计算f1_score的时候要采用其他的策略：</p> 
<p>transformerer_local/data/metrics/__init__.py，注意这里的transformerer_local原本应该是transformerer，添加内容：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#添加多分类评价函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">acc_and_f1_multi</span>(<span class="hljs-params">preds, labels</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        acc = simple_accuracy(preds, labels)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        f1 = f1_score(y_true=labels, y_pred=preds,average=<span class="hljs-string">'micro'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> {</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-string">"acc"</span>: acc,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-string">"f1"</span>: f1,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-string">"acc_and_f1"</span>: (acc + f1) / <span class="hljs-number">2</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        }</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">glue_compute_metrics</span>(<span class="hljs-params">task_name, preds, labels</span>):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">assert</span> len(preds) == len(labels)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> task_name == <span class="hljs-string">"cola"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"mcc"</span>: matthews_corrcoef(labels, preds)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"sst-2"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"acc"</span>: simple_accuracy(preds, labels)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"mrpc"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> acc_and_f1(preds, labels)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"sts-b"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> pearson_and_spearman(preds, labels)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"qqp"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> acc_and_f1(preds, labels)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"mnli"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"acc"</span>: simple_accuracy(preds, labels)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"mnli-mm"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"acc"</span>: simple_accuracy(preds, labels)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"qnli"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"acc"</span>: simple_accuracy(preds, labels)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"rte"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"acc"</span>: simple_accuracy(preds, labels)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"wnli"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"acc"</span>: simple_accuracy(preds, labels)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"hans"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> {<span class="hljs-string">"acc"</span>: simple_accuracy(preds, labels)}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment">#添加我们的多分类任务调用函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">elif</span> task_name == <span class="hljs-string">"myown"</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">return</span> acc_and_f1_multi(preds, labels)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">else</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">raise</span> KeyError(task_name)</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>添加内容就在注释部分。</p> 
<p>OK，现在代码部分已经做好了，接下来就是数据部分了。直接上数据：</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200509153617413.png"></p> 
<p>数据截图部分就是上面这样的，把pat_summary和ipc_class属性提取出来，这里的数据质量比较好，然后只需要把超级长的文本去掉(长度大于510的)：</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20200509153915967.png"></p> 
<p>数据长度分布直方图，发现几乎全部都是小于510的长度，只有少部分比较长，只有128条，这里数据集总规模是24.8W条，可以把这少部分的直接去掉。然后把数据分割成训练集和测试集比例(8:2)，保存为tsv格式。</p> 
<p>接下来就是直接进行训练了，编写如下命令行，在train_glue_classification.sh文件中：</p> 
<pre><code class="language-python hljs"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">export TASK_NAME=myown</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">python -W ignore ./examples/run_glue.py \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --model_type bert \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --model_name_or_path ./pretrain_model/Chinese-BERT-wwm/ \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --task_name $TASK_NAME \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    __do_train \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --do_eval \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --data_dir ./data_set/patent/ \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --max_seq_length <span class="hljs-number">510</span> \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --per_gpu_eval_batch_size=<span class="hljs-number">8</span>  \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --per_gpu_train_batch_size=<span class="hljs-number">8</span>   \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --per_gpu_predict_batch_size=<span class="hljs-number">48</span> \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --learning_rate <span class="hljs-number">2e-5</span> \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --num_train_epochs <span class="hljs-number">5.0</span> \</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    --output_dir ./output/</div></div></li></ol></code><div class="hljs-button signin" data-title="登录后复制" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.4259&quot;}" onclick="hljs.signin(event)"></div></pre> 
<p>直接在终端上运行这个sh文件，bash train_glue_classification.sh。注意这里的训练显卡显存得11G以上，不然跑步起来，batch_size不能太大。训练过程中，一个epoch大概时间3.5小时，所以时间还要蛮久的。最后给出结果：</p> 
<p><img alt="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/2020050915520712.png"></p> 
<p>可以看到acc=0.8508，一个8分类的任务准确率85%粗略一看还能接受。如果要详细的分析，可以把每一类的准确率和召回率给弄出来，或者分析一下ROC，对模型的性能做详细的分析，这里不做过多讨论。另外关于这个模型的优化，怎么提高准确率，也不做考虑。</p> 
<p>&nbsp;</p> 
<p>小结：以上就是直接使用transformers项目中的bert分类器拿过来进行fine-tune，做文本分类，其实代码都写好了，我们只需要简单的修改一下代码和配置，就能很快的训练好自己的分类器。</p> 
<h1 id="%E5%9B%9B%E3%80%81Bert%E6%A8%A1%E5%9E%8B%E9%9A%BE%E7%82%B9%E6%80%BB%E7%BB%93"><a name="t13"></a><a name="t13"></a>四、Bert模型难点总结</h1> 
<p>其实关于Bert模型还有很多细节可以去探究，这里推荐知乎上的一些文章：<a href="https://zhuanlan.zhihu.com/p/132554155">超细节的BERT/Transformer知识点</a>。</p> 
<p>1、Bert模型怎么解决长文本问题？</p> 
<p>如果文本的长度不是特别长，511-600左右，可以直接把大于510的部分直接去掉，这是一种最粗暴的处理办法。</p> 
<p>如果文本内容很长，而且内容也比较重要，那么就不能够这么直接粗暴的处理了。主要思路是global norm + passage rank + sliding window——来自Amazon EMNLP的这篇文章：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1908.08167.pdf">Multi-passage BERT</a>。简单的说一下sliding window，滑窗法就是把文档分割成有部分重叠的短文本段落，然后把这些文本得出的向量拼接起来或者做mean pooling操作。具体的效果，要去做实验。</p> 
<p>2、Bert的输入向量Token Embedding、Segment Embedding、Position Embedding，它们都有自己的物理含义，为什么可以相加后输入到模型中取呢？</p> 
<p>这个问题在知乎上已经有人提问了，回答的大佬很多。我个人倾向接受这个解释：one hot向量concat后经过一个全连接等价于向量embedding后直接相加。</p> 
<p>Token Embedding、Segment Embedding、Position Embedding分别代表了文本的具体语义，段落含义和位置含义，现在要把这3个不同的向量一起放到模型中去训练，我认为concat的操作就能完整的保留文本的含义。[input_ids] 、[token_type_ids] 和[position_ids]这3个向量，concat以后形成一个[input_ids token_type_ids position_ids]新的向量，这样丢入模型中取训练就应该是我们初始要的结果。但是在丢入模型之前这个向量[input_ids token_type_ids position_ids]是需要经过Embedding的，而[input_ids] 、[token_type_ids] 和[position_ids]先经过Embedding然后相加和上面的效果是等价的。这样的好处是降低了参数的维度的同时达到了同样的效果，所以就采用了直接相加。</p> 
<p>3、BERT在第一句前会加一个[CLS]标志，为什么？作用是什么？</p> 
<p>最后一层的transformer的输出该位置的向量，由于本身并不具有任何意义，就能很公平的融合整个句子的含义，然后做下游任务的时候就很好了。</p> 
<p>其实在huggingface实现的bert代码中，作者认为这个向量并不是很好，要想做下有任务，还是得靠自己取把最后一层的hidden_states[B,S,D]去做一些操作，比如mean pool操作。我这里没有实验过，只是拿来使用，在<a href="https://blog.csdn.net/HUSTHY/article/details/103767932">使用bert模型做句子分类</a>一文中使用了这样的思想。</p> 
<p>4、Bert模型的非线性来自什么地方？</p> 
<p>主要是来子前馈层的gelu激活函数和self-attention。</p> 
<p>5、Bert模型为何要使用多头注意力机制？</p> 
<p>谷歌bert作者在论文中提到的是模型有多头的话，就可以形成多个子空间，那么模型就可以去关注不同方面的信息。</p> 
<p>可以这样理解，多头attention机制确实有点类似多个卷积核的作用，可以捕捉到文本更多更丰富的信息。</p> 
<p>当然知乎有人专门研究这个问题，列举了头和头直接的异同关系，作了一个比较综合全面的回答，可以去阅读！<a href="https://www.zhihu.com/question/341222779">为什么Transformer 需要进行 Multi-head Attention？</a></p> 
<p>&nbsp;</p> 
<p>写在最后：</p> 
<p>我个人理解的Bert模型就只有 这么多，其实Bert模型就是一个提取词向量的语言模型，由于提取的词向量能很好的包含文本的语义信息，它能够做很多任务并且取得不错的效果。NER、关系抽取、文本相似度计算、文本分类、阅读理解等等任务Bert都能做。</p> 
<p>这个博客个人算是花了一定的精力了的(五一到现在，差不多10天时间吧)，作为这段时间以来学习NLP的一个总结还是很有收获感的。加油！继续努力！当然博客可能写的不是干货，也许还有错误的地方，作者水平有限，望大家提出改正！</p> 
<p>&nbsp;</p> 
<p>参考文章</p> 
<p><a href="https://blog.csdn.net/jiaowoshouzi/article/details/89073944">一文读懂bert模型</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/132554155">超细节的BERT/Transformer知识点</a></p>
                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/105882989&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>
        </div>
    </article>
</div>
<script>
    // 敏感词替换
    // replaceArticleContentWords(blogSensitiveWords,'sensitiveWords')
    // 高亮词
    // replaceArticleContentWords(blogHotWords,'hotWords')
    // 公共方法
    function replaceArticleContentWords(words,type){
      if(words){   
        var getContentViews = document.getElementById("content_views");
        var getContentTitle = document.getElementById("articleContentId");
        var contentViewsInnerHTML = getContentViews.innerHTML;
        var contentTitleInnerHTML = getContentTitle.innerHTML;
        var keyWordsJsonArr = [];
        var keyWordsArr = words.split(',');
        function repeatTimes(str, num){
            return num > 1 ? str += repeatTimes(str, --num): str;
        }
        for(var i = 0; i < keyWordsArr.length; i++){
            var keyWordsJson = {} ;
            keyWordsJson.key = keyWordsArr[i];
            if(type == 'hotWords'){
              keyWordsJson.value = '<span class="hot-words-highlight">'+keyWordsArr[i]+'</span>'
            }else if(type == 'sensitiveWords'){
              keyWordsJson.value = repeatTimes("*",keyWordsArr[i].length);
            }else {
              keyWordsJson.value = keyWordsArr[i]
            }
            keyWordsJsonArr.push(keyWordsJson);
        }
        var reg;
        for(var i = 0; i < keyWordsJsonArr.length; i++){
            var item = keyWordsJsonArr[i]; 
            if(type == 'hotWords'){
              reg = new RegExp(item.key,"ig");
            }
            if(type == 'sensitiveWords'){
              reg = new RegExp(item.key+"(?!([^<]*>)|([^<]*<\/a>))","ig");  
            }
            contentViewsInnerHTML = contentViewsInnerHTML.replace(reg,item.value);
            contentTitleInnerHTML = contentTitleInnerHTML.replace(reg,item.value);
        }
        getContentViews.innerHTML=contentViewsInnerHTML;
        getContentTitle.innerHTML=contentTitleInnerHTML;
      }
    }
</script>
<div class="more-toolbox more-toolbox-active" id="toolBarBox">
    <span id="fixedBar"></span>
    <div class="left-toolbox" style="position: fixed; left: 388px; bottom: 0px; width: 900px;">
        <ul class="toolbox-list">
            <li class="tool-item tool-item-size tool-active is-like" id="is-like"><a>
            <img style="display:none;" id="is-like-imgactive-animation-like" class="animation-dom active-animation" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarThumbUpactive.png" alt="">
            <img class="isactive" style="display: none;" id="is-like-imgactive" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarThumbUpactive.png" alt="">
            <img class="isdefault" style="display: block;" id="is-like-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarThumbUp.png" alt="">   
            <span class="name" id="is-like-span" style="">点赞</span>
            <span id="spanCount" class="count" style="">
                    7
            </span>
            </a></li>
            <li class="tool-item tool-item-size tool-active tool-item-comment">
                <a href="https://blog.csdn.net/HUSTHY/article/details/105882989#commentBox">
                    <img class="isdefault" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarComment.png" alt="" style="display: block;">
                    <img class="isactive" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarCommentactive.png" style="display: none;" alt="">
                    <span class="name">评论</span>
                    <span class="count">
                        10
                    </span>
                </a>
            </li>
            <li class="tool-item tool-item-size tool-active tool-QRcode" id="tool-share" data-flag="">
                <a href="javascript:;" data-report-click="{&quot;mod&quot;:&quot;1582594662_002&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4129&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img class="isdefault" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarShare.png" alt="">
                    <img class="isactive" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarShareactive.png" style="display:none;" alt="">
                    <span class="name" style="">分享</span>
                </a>
                <div class="QRcode" id="tool-QRcode" style="left:-92%;">
                    <span id="QRcode-close">x</span>
                    <p class="title">
                    海报分享
                    </p>
                    <div id="shareCode" title="https://blog.csdn.net/HUSTHY/article/shareArticleCardPage?article_id=105882989&amp;utm_source=po_popup"><canvas width="144" height="144" style="display: none;"></canvas><img style="display: block;" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJAAAACQCAYAAADnRuK4AAAN/0lEQVR4Xu2d23bbOgxE2///6J7l2O6RFBB7g2TSOEGfuiKJF2AwGEAX//7169efX4v//vz5f4jfv3+/G+14PJvqea0dL5rrNv7zelrL6PrrGrPxov1E66c9WRfMjB3Z3+6d1nXzdgMIrNQAGhvoL4AsSxyHyhiDxssigK6NtnMcL3J4FoU0X7RPiszncRvpxCy05+fx3XuneRtAh5Q3AkUD6GyZY1A0gBpAlkz/nocAsunFRmZ2HgldI7qPwvn2/2xMSinVFHBcX5YKad5oHLJNteiw8sMWBm+2fopoWyWs5GpbDZAmifQFrd8K4QZQHLIj+24H0A5WIk6lOaoMuhL9u64lJqM9X20WFRUvwUB2o/a8rAoYMVUD6JzGbQU6Y7dmoAtCV5qQK9c2Az0sYJllBu3XXgeluhXKtmOT9iJBaouEbO+7emAzPvnnDEQGpkrEOtpWLHa8yKG20popEl4KQNaImVMoMrNqhxxRragqpb0txVfOs/sjBo2qUcvSNlNkGnRYxjeAYgtQZRM51LYuVjTQDEs3gAYNw5EjbHNxhVl+NIAs61jNQg3Havqz493WZ9PjVzzvmG7tnlfOW/H7KYWtDLSygd3XNoDuz2NZu674/Q1Af2xJUJzJ6gUSaVm1Q0u3a9h9HonfGRGdmX/3eBVXN4AuWmqHBmoAVSA4ONdGdTPQewsQs16v+LIMRCCwpWB2np0jqq7oWooDMnx2/Q6mWpmf9mZBSGugnluawshBDaDYjWS3qNwnQFSPfxqAsueBZrrJkejdIQCpWRY5bcaRK6V9JvgrDGoZO7JrlRktA0W67q0KawDFjz5YQFaAfQXYCOANIPGcsaXxmUckMhYh0d4MdLYQ3YoJNVC1S1yl0hEdZumvEunZpmfS8gogbVqjFGdtszuF0fobQBf0VxmIGI0ckAUfBU3E4p8OoOjN1BUj2puWVdYiY9rjRMnWobtZjqqsFWDsXuuJxRtA8WtAlFJ2O6UB9LBAM1B8I5MA+bIAet5MnUkBVmxXczXpCpuGrGC28+0u7Svro35NJrJpfxl4ydZ/RXQD6GzGGbBUWw7fAkC7NVCG9pn2+so1BAJbIVWLCmILiuod883MYZnouL/w+0DVDVD+tvfMVlIdgaXKDqRZrI1stTmzfrunzK4EdgqyBtDg6b0G0Bn6o3SrNVCEYhtd2bU2RVmWu51nO8fVe06REe3fLCBv59l1VVmQNBfZOGQjW4U1gPxzxuQoAvjLA4gEWLVkrIKP9ADlZRtJVjTuLgxofbZJSeMY5idbExbCFEYXNYDyNJMBzji9ATSwEin+f5XTq1qOdMqPBNBx07bDXL1tMaMNbLoiMVtNQ9RYzZiEAoVYiDSSSU3kz6qsGK15++MctjfxUeCrsIMVq9WU3QB6fG3eltgUrasGvaKfIrQ6n9V8x3VY20SRngXZ7Xza33VMWj8dXyomojdTVzrHNuUQjZtNRRXEkYHsHDMGbgDdratTWDXnk96xzs0EbgPo/XvwGeNFuoj8QIGib2UYRhgKLfkDLFVNMpqvWgbblGeFOvVWyGnVoLHzEdNSao3W1QAS3xnK0vJHOOUlATRjCNu3sYyQtQ8iAWuZ4yhMIxq3zEIpYEX8EotYG1p2s1UwsVL6Wxl2U/a8GefZjZLhrANsAWHXVZ13VxVG9qiufxSsDSDxMaYw9ye6biTurwJ3VGisMBkBJxLZ1xRNhHAigqyMj9IGsYhZ4O0cm65mxLvtpFtgRBoo22emYXbtndIypXzb8CVApmV8A+hsPtKJFuw7gqcBFHS7K6J4ZECKcOxrBKmpGWgcGukTiURflgYzYOx26BFAM6lkJQVn9iJdFEkDygDkH3Oc1kVB3QAafEnE3t+jAIgASdfQ3AYY9pwPBZDN+XReZjDawIohKHpsHytKYbu65lXdRKxULc+tfUcMueWh+gbQ2Q0EXOs0up9Idr8C/yOCtQE0+MwvpZFmoDs8y89EV1FP0UbRaoV6NI8d265xZu8WaKSLMi1lmYXOI3uFNo5e67Htd1ux2Ookq5qIERpAdwus6M0pANl34zMhScIucy5FnhWF0RpsS95qDRvBK3t6SwtJL4rYkua+Bj3dSKamZ/lxDmts2mhG7SPFn4nCBhAzUGTXBlCA1B3luQUkOcWmVgpMCsgoQxjp8CEAyrQIGcSKXqtp7HnEWtbAK6LXsiqBwe45Sy82lZHdsmB8S7eRBmoAxWJ0lwb6VgDKqrBdYs6OU63+bPTMOIyuqQZZZa07mMXanPZJTJb2gVYWMZPTG0B3dzaAxEebbARbXWF1A2k4isjsOEXr81pa60sCiAy3w5EzfRnrcMt41E22jbhMlNM+Z4C2g51pXuvjUzq2v5lqB7eNP1utNYDuFviyAIp+7ilzmu0bHMfIwELMZxmBoiubxzIGpZ4oRX3k+m2wRmxZTZMjPZy+lRFVDg2gMxR3pcSZAGgAEf0s3hwUw5+qnmOqIFaqaiBKxd8SQJayKz0Ok0qI5awzbOMvSrc0xwqArF1p/caWdm+382a68PrFwsxgDaCzK8nx3wpA2Wd+bQqIzqOyuiourdFHYK7eYKW926ooa8aObFBlgpWGr93nUEQ3gOaev2kA3aG39FpPht5moIeBiy8qzmiRf8pAWR/Ipo2ZisWO/QQpzWHLadInVfFM49kGLKUSezzr79AYVlacZEIDiMwap7hMU0U6bKZM55W9P+PTAZTdypihxpVbFNZgM1FthamtNi0zZgUG2dfKABrHSo1sT6Mxwq9zRANZ5zaAWJTbWzsNoAvqdtF4M9DdsBaIH8pA9pHWjIpJeM6Is+uY1J0mUV5NYcf5Latm+qMSPDZA7J5sy8GmsKOt9TPRDaBcTI/KbwuGGeH9pQBEEZ6xjI0uW/JG0V9hOWKj61gkQu3+Mu1I9qU1ZOKe9ltlRruWt6CJyngbNfa8GWo01dAIkGTQBpC/cUrFUwNIvErcDDSGUfmBMkovlv6qwo40gmUdm0Yp5WSRSWuxx20Zb21j9xTZaOTXBtAFCVW9QNosSsU/EkCZQLSsRBGVVXrEHFEUUilu2ws2hWXsS3sndsiATfvMQGzvIY4YVzNQA4jkZN6BbgA97Ecax2obGucaNc1A738bLEuFM2nSVssntrfvxu+g8ZlUZ5mP+MHePbfzVcej9ZEQztZl09+K/UcSQb8b3wA6Q6ABdLeH/q2MmWqiEnUjhFtHUYpbafvbSiuykWWOmSIgKzqs7a2UGLFXA2jwmV9ygK24GkAXS1aqCXLC6Dg1smZKz2ag2NrLDJR9pdXSKgnA3dFKFUYU9VkqtOPRPq0At3KARG+WWklYzzBjdE36ldYG0JhDLaNlLExs3gB6WKAZKIbRjwdQtQqgfBulmeoct/MtO1RbE6S9siosSzfXY3aeLBXS3qpBPdSrKxqo6twG0NliI3u8FIDsaz22H7Mizuy1dGPROsDedsl0DAWFFcy0ZrtWu54qWw4ZqAEUswKlgN0VVwPoAtGZ0rgZaJziviwDWQ1kI66a6khc2vGo+Vgtp4kRquNl59+O2b7NcRxK5TTndd6ZVK37QA0gfuPU6h0qPrIq8ssCqNKTyARY9RmVo0F2RX01FUZrIDE6w4yWtYiVZ8ehPVm/nrCSvdZDFGgdvtLf2bVpyw7VtdqnAGZsGbHNyji7bNkAenhhB1v+eABFZbzt5FIuvx4noZuVzitV3W0dtvNq9ceONEOMQLLC2itjVduuGDFf+jyQTVGkYyJNYjWE1TNE7Q0gfrefbBgGTfXrHBZUM2WpBRoxn2WRrAymfVYDgBhrZT7L7JbFabyTNmsA+R4MGbaaDir6KQOsXVcDKOHYGcZrBvI/7TmSAOWPK1gUUwm6u1xeabDZ9EFpyPZnrA2JWWxrIjvPsmYDqPi9Zkovmbi3Go2Kj5cCkFXgFrGWESj12DRDJXEUhZlop/Vn9rLgszYfsbkt4wnQ1XUc91f+xF0DiM3dAJJilU15P6PKIiusRGua0Tu2LWAZjda4g92IkWeIINpf+p1o2mgVGDbnk5MtJVsmIGPPzGcFtdVStpuc+YT8afd5Sqn2R3ejwRtAZ6tYIK4ECFVwLwWgDFQzbLOSKmaiqxpxBJAqS5CN7J5mQLWLEJZSWAPobIEGkIV8ch5FwzXnk2C2gnLD0t+G2FEakw3oeHUvNJ5l9hlJUi7jq7Q/MkZ1UzQvNd2s7rD3nLL1kEMJINn1tjA4Cd1HE5WC1eqn0zjVm6nkSDJOxkA2JT7PiwxyZBEydtVRuzQQ2ai6LjvehwJopi9gWeQKmkqqyJhjtOYqAxDQovVHILYBUGXD27gZeGfGsyI62/vburJfLJxBttUsVms0gO4WbQAVvgRGjEDM1ww09/RhZtcRgNPHOUjvzExoqT/TSgQQKwaJYc1xqyuOY9GjLFZOkB0o/VT3F6a96ms9ZDC76KqRRoI5E9R0jTEgnUP2sII4AhjN/S0BZFnJCr9dAKmW57Q+YpHruqmCswxl13Ucrwo0muM09m4GagCdecMCrQH0sEADqAGkS8YVsNg+BFVcpBOux22FR4xgmaWSDrICw6Yhq0GrdhvpyU+pwnYIZjsGGaYBRBaKj5cAZKewDBSN9xUaiVm5T9VVZqMIpPQ3slFFhF/HqhYQlYrwwzrRtOEGEH9vaFcbogF0CSnSRVYvNAPVQBzq1s+4G2+baTtY6bZJK1yrkUnj0nErku26MiFPmpGCMBPjJ2ZsAJ2jsOqUFVE+avY1gAYpx5bGWYlvGKbKBFbg0rh0/Dsy0H83xBrQelc/7QAAAABJRU5ErkJggg=="></div>
                    <p>
                    扫一扫，分享海报
                    </p>
                </div>
            </li>
            <li class="tool-item tool-item-size tool-active is-collection ">
                <a href="javascript:;" data-report-click="{&quot;mod&quot;:&quot;popu_824&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4130&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img style="display:none" id="is-collection-img-collection" class="animation-dom active-animation" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarCollectionActive.png" alt="">
                    <img class="isdefault" id="is-collection-img" style="display:block" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarCollect.png" alt="">
                    <img class="isactive" id="is-collection-imgactive" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarCollectionActive.png" alt="">
                    <span class="name" id="is-collection">收藏</span>
                    <span class="count get-collection" id="get-collection">
                        27
                    </span>
                </a>
            </li>
            <li class="tool-item tool-item-size tool-active tool-reward">
                <a id="toolreward" data-report-click="{&quot;mod&quot;:&quot;popu_830&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4237&quot;,&quot;dest&quot;:&quot;&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img class="isdefault" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarReward.png" alt="">
                    <img class="isactive" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarRewardactive.png" style="display:none;" alt="">
                    <span class="name">打赏</span>
                </a>
<div id="reward" class="reward-box">
	<p class="rewad-title">打赏<span class="reward-close"><svg t="1567152543821" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="10924" xmlns:xlink="http://www.w3.org/1999/xlink" width="12" height="12"><defs><style type="text/css"></style></defs><path d="M512 438.378667L806.506667 143.893333a52.032 52.032 0 1 1 73.6 73.621334L585.621333 512l294.485334 294.485333a52.074667 52.074667 0 0 1-73.6 73.642667L512 585.621333 217.514667 880.128a52.053333 52.053333 0 1 1-73.621334-73.642667L438.378667 512 143.893333 217.514667a52.053333 52.053333 0 1 1 73.621334-73.621334L512 438.378667z" fill="" p-id="10925"></path></svg></span></p>
	<dl>
		<dd>
		<a href="https://blog.csdn.net/HUSTHY" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY&quot;,&quot;ab&quot;:&quot;new&quot;}">
			<img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_husthy" class="avatar_pic">
		</a>
		</dd>
		<dt>
			<p class="blog-name">colourmind</p>
			<p class="blog-discript">你的鼓励将是我创作的最大动力</p>
		</dt>
	</dl>
	<div class="change-bt-box">
		<span class="reward-bt reward-bt-coin">C币</span>
		<span class="reward-bt-space"></span>
		<span class="reward-bt reward-bt-money reward-bt-active">余额</span>
	</div>
	<div class="money-box">
			<span class="choose_money choosed" data-id="2">¥2</span>
			<span class="choose_money " data-id="4">¥4</span>
			<span class="choose_money " data-id="6">¥6</span>
			<span class="choose_money " data-id="10">¥10</span>
			<span class="choose_money " data-id="20">¥20</span>
			<span class="choose_money " data-id="50">¥50</span>
	</div>
	<div class="sure-box">
		<p class="is-have-money"><span class="tip">您的余额不足，请先充值哦～</span><a class="bt-go" data-report-click="{&quot;mod&quot;:&quot;1597646289_003&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4302&quot;}" target="_blank" href="https://i.csdn.net/#/wallet/balance/recharge" data-report-query="utm_source=RewardVip">去充值</a></p>
	</div>
</div>
            </li>
            <li class="tool-item tool-item-size tool-active tool-more">
              <a class="article-report">
                <img class="isdefault" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarReport.png" alt="" style="display: block;">
                <img class="isactive" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tobarReportactive.png" style="display: none;" alt="">
                <span class="name">举报</span>
              </a>
            </li>
            <li class="tool-item">
                    <a class="tool-attend tool-bt-button tool-bt-attend" href="javascript:;">关注</a>
                <a class="tool-item-follow active-animation" style="display:none;">关注</a>
            </li>
            <li class="tool-item">
                    <p class="company active" id="health-companies" href="javascript:;">一键三连</p>
                <span class="triplet-prompt" style="display: inline;">点赞Mark关注该博主, 随时了解TA的最新博文<img class="close-prompt" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/closePrompt.png"></span>
            </li>
        </ul>
        <div style="display:flex">
         </div>
         <div class="hot-word-tip-box">
          <span class="hot-word-text">已标记关键词</span>
          <span class="hot-word-count"></span> 
          <span class="hot-word-bar"></span>
          <span class="hot-word-clear">清除标记</span>
        </div>
    </div>  
</div>
<script type="text/javascript" crossorigin="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/qrcode-7c90a92189.min.js.下載"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/saved_resource(4)" type="text/javascript"></script>
<script type="text/javascript" crossorigin="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/collection-box.js.下載"></script>
                <div class="first-recommend-box recommend-box">
<div class="recommend-item-box type_other clearfix" data-url="https://edu.csdn.net/topic/python115" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.476313\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;32_476313_RCMD&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/topic/python115&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://edu.csdn.net/topic/python115" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.476313\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;32_476313_RCMD&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/topic/python115&quot;}" data-report-query="utm_medium=distribute.pc_relevant_t0.476313&amp;depth_1-utm_source=distribute.pc_relevant_t0.476313">
					Pandas可视化综合指南：手把手从零教你学会绘制数据图表
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info display-flex">
					<span class="info-block">12-23</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://edu.csdn.net/topic/python115" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.476313\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;32_476313_RCMD&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/topic/python115&quot;}" data-report-query="utm_medium=distribute.pc_relevant_t0.476313&amp;depth_1-utm_source=distribute.pc_relevant_t0.476313">
				<div class="desc ellipsis-online ellipsis-online-1">数据可视化本来是一个非常复杂的过程，但随着Pandas数据帧plot()函数的出现，使得创建可视化图形变得很容易。</div>
			</a>
		</div>
	</div>
</div>
                </div>
            <div class="second-recommend-box recommend-box">
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/xpy870663266/article/details/105398637" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;BlogCommendFromBaidu&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/xpy870663266/article/details/105398637&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/xpy870663266/article/details/105398637" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;BlogCommendFromBaidu&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/xpy870663266/article/details/105398637&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control">
					<em>Transformers</em><em>源码</em><em>阅读</em>——<em>Bert</em>Model
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/xpy870663266" target="_blank"><span class="blog-title">pyxiea</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">04-08</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					505
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/xpy870663266/article/details/105398637" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;BlogCommendFromBaidu&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/xpy870663266/article/details/105398637&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control">
				<div class="desc ellipsis-online ellipsis-online-1"><em>Bert</em>Model类的结构图如下：


</div>
			</a>
		</div>
	</div>
</div>
            </div>
<a id="commentBox" name="commentBox"></a>
<div class="comment-box">
	<div class="comment-edit-box d-flex">
		<a id="commentsedit"></a>
		<div class="user-img">
			<a href="javascript:void(0);">
				<img class="show_loginbox" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/anonymous-User-img.png">
			</a>
		</div>
		<form id="commentform">
			
      <textarea class="comment-content" name="comment_content" id="comment_content" placeholder="优质评论可以帮助作者获得更高权重" maxlength="1000"></textarea>
			<div class="comment-emoticon"><img class="comment-emoticon-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/emoticon.png" alt="表情包"></div> 
      <span class="comment-emoticon-tip">插入表情</span>
      <div class="comment-emoticon-box" style="display: none;">
        <div class="comment-emoticon-img-box">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:001.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/001.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:002.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/002.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:003.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/003.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:004.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/004.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:005.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/005.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:006.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/006.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:007.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/007.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:008.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/008.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:009.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/009.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:010.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/010.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:011.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/011.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:012.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/012.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:013.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/013.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:014.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/014.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:015.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/015.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:016.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/016.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:017.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/017.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:018.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/018.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:019.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/019.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:020.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/020.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:021.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/021.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:022.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/022.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:023.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/023.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:024.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/024.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:025.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/025.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:026.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/026.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:027.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/027.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:028.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/028.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:029.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/029.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:030.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/030.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:031.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/031.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:032.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/032.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:033.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/033.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:034.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/034.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:035.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/035.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:036.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/036.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:037.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/037.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:038.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/038.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:039.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/039.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:040.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/040.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:041.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/041.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:042.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/042.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:043.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/043.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:044.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/044.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:045.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/045.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:046.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/046.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:047.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/047.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:048.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/048.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:049.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/049.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:050.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/050.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:051.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/051.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:052.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/052.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:053.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/053.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:054.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/054.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:055.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/055.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:056.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/056.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:057.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/057.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:058.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/058.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:059.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/059.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:060.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/060.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:061.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/061.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:062.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/062.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:063.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/063.png">
            <img class="emoticon-monkey-img" data-emoticon="[face]monkey2:064.png[/face]" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/064.png">
        </div>
      </div>
      <div class="opt-box">
				<div id="ubbtools" class="add_code">
					<a href="https://blog.csdn.net/HUSTHY/article/details/105882989#insertcode" code="code" target="_self"><i class="icon iconfont icon-daima"></i></a>
				</div>
				<input type="hidden" id="comment_replyId" name="comment_replyId">
				<input type="hidden" id="article_id" name="article_id" value="105882989">
				<input type="hidden" id="comment_userId" name="comment_userId" value="">
				<input type="hidden" id="commentId" name="commentId" value="">
				<div class="dropdown" id="myDrap">
					<a class="dropdown-face d-flex align-items-center" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">
						<div class="txt-selected text-truncate">添加代码片</div>
						<svg class="icon d-block" width="200px" height="100.00px" viewBox="0 0 2048 1024" version="1.1" xmlns="http://www.w3.org/2000/svg"><path d="M597.33333292 298.666667h853.333334L1023.99999992 725.333333 597.33333292 298.666667z"></path></svg>
					</a>
					<ul class="dropdown-menu" id="commentCode" aria-labelledby="drop4">
						<li><a data-code="html">HTML/XML</a></li>
						<li><a data-code="objc">objective-c</a></li>
						<li><a data-code="ruby">Ruby</a></li>
						<li><a data-code="php">PHP</a></li>
						<li><a data-code="csharp">C</a></li>
						<li><a data-code="cpp">C++</a></li>
						<li><a data-code="javascript">JavaScript</a></li>
						<li><a data-code="python">Python</a></li>
						<li><a data-code="java">Java</a></li>
						<li><a data-code="css">CSS</a></li>
						<li><a data-code="sql">SQL</a></li>
						<li><a data-code="plain">其它</a></li>
					</ul>
				</div>
				<div class="right-box" id="rightBox" data-type="2">
							<span id="tip_comment" class="tip">还能输入<em>1000</em>个字符</span>
							<a data-report-click="{&quot;spm&quot;:&quot;3001.4374&quot;}" class="btn btn-sm btn-quick-comment" id="quickComment">“速评一下”</a>
							<a data-report-click="{&quot;mod&quot;:&quot;1582594662_003&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4227&quot;,&quot;ab&quot;:&quot;new&quot;}"><input type="submit" class="btn btn-sm btn-comment" value="发表评论"></a>
				</div>
			</div>
		</form>
		<input type="button" class="bt-comment-show" value="评论">
	</div>
	<div class="comment-list-container" style="display: block;">
		<a id="comments"></a>
		<div class="comment-list-box" style="overflow: hidden; max-height: 311px;"><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="13072834" data-replyname="weixin_43935009"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/weixin_43935009"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_weixin_43935009" username="weixin_43935009" alt="weixin_43935009" class="avatar"></a>        <div class="right-box ">          <div class="new-info-box clearfix">            <a target="_blank" href="https://blog.csdn.net/weixin_43935009"><span class="name ">weixin_43935009</span></a><span class="colon">:</span><span class="floor-num"></span><span class="new-comment">我想问一下 如果是自己训练得到的模型 想在--model_name_or_path ./pretrain_model/Chinese-BERT-wwm/  这里改成自己训练的模型的位置的话 应该怎么写？</span><span class="date" title="2020-08-18 19:40:57">4月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="13072834"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span></span></div></div></div></li><li class="replay-box" style="display:block"><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="13077420" data-replyname="HUSTHY"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/HUSTHY"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_husthy" username="HUSTHY" alt="HUSTHY" class="avatar"></a>        <div class="right-box reply-box">          <div class="new-info-box clearfix">            <a target="_blank" href="https://blog.csdn.net/HUSTHY"><span class="name mr-8">colourmind<img class="is_bloger" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/bloger@2x.png"></span></a><span class="text">回复</span><span class="colon">:</span><span class="text"></span><span class="new-comment">我这里的--model_name_or_path ./pretrain_model/Chinese-BERT-wwm/ 含义就是：传入路径在./pretrain_model/Chinese-BERT-wwm/下面的模型。你要想使用这里的方法的话，只需要更改模型路径为你自己的模型路径就好了。</span><span class="date" title="2020-08-19 13:52:19">4月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="13077420"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span>1</span></div></div></div></li></ul></li></ul><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="12975323" data-replyname="weixin_45414476"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/weixin_45414476"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_weixin_45414476" username="weixin_45414476" alt="weixin_45414476" class="avatar"></a>        <div class="right-box ">          <div class="new-info-box clearfix">            <a class="comment-tag" target="_blank" href="https://blog.csdn.net/blogdevteam/article/details/103478461">码哥<img class="comment-tag-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentTagArrowWhite.png" title="码哥"></a><a target="_blank" href="https://blog.csdn.net/weixin_45414476"><span class="name ">weixin_45414476</span></a><span class="colon">:</span><span class="floor-num"></span><span class="new-comment">感谢博主，先来个三连！另外请教一下，bertpretrainedmodel所继承的pretrainedmodel类的代码在哪个文件里呢？</span><span class="date" title="2020-08-05 15:14:16">4月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="12975323"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span></span></div></div></div></li><li class="replay-box" style="display:block"><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="12976130" data-replyname="HUSTHY"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/HUSTHY"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_husthy" username="HUSTHY" alt="HUSTHY" class="avatar"></a>        <div class="right-box reply-box">          <div class="new-info-box clearfix">            <a target="_blank" href="https://blog.csdn.net/HUSTHY"><span class="name mr-8">colourmind<img class="is_bloger" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/bloger@2x.png"></span></a><span class="text">回复</span><span class="colon">:</span><span class="text"></span><span class="new-comment">这个你自己直接在transformers库里搜索一下就OK了</span><span class="date" title="2020-08-05 16:11:34">4月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="12976130"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span></span></div></div></div></li></ul></li></ul><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="12877000" data-replyname="Dawang_0v0"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/Dawang_0v0"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_dawang_0v0" username="Dawang_0v0" alt="Dawang_0v0" class="avatar"></a>        <div class="right-box ">          <div class="new-info-box clearfix">            <a target="_blank" href="https://blog.csdn.net/Dawang_0v0"><span class="name ">Dawang_0v0</span></a><span class="colon">:</span><span class="floor-num"></span><span class="new-comment">博主你好，请问这个图是拿什么软件做的</span><span class="date" title="2020-07-23 15:24:42">5月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="12877000"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span></span></div></div></div></li></ul><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="12753933" data-replyname="weixin_45715267"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/weixin_45715267"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_weixin_45715267" username="weixin_45715267" alt="weixin_45715267" class="avatar"></a>        <div class="right-box ">          <div class="new-info-box clearfix">            <a target="_blank" href="https://blog.csdn.net/weixin_45715267"><span class="name ">�R??</span></a><span class="colon">:</span><span class="floor-num"></span><span class="new-comment">感谢博主，很用心。。学习了</span><span class="date" title="2020-07-08 22:21:27">5月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="12753933"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span></span></div></div></div></li></ul><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="12425944" data-replyname="weixin_41667774"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/weixin_41667774"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_weixin_41667774" username="weixin_41667774" alt="weixin_41667774" class="avatar"></a>        <div class="right-box ">          <div class="new-info-box clearfix">            <a target="_blank" href="https://blog.csdn.net/weixin_41667774"><span class="name ">佛系</span></a><span class="colon">:</span><span class="floor-num"></span><span class="new-comment">mark,有时间仔细看看，很强啊</span><span class="date" title="2020-06-02 23:22:44">6月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="12425944"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span></span></div></div></div></li><li class="replay-box" style="display:block"><ul class="comment-list"><li class="comment-line-box d-flex" data-commentid="12427339" data-replyname="HUSTHY"><div style="display: flex;width: 100%;">      <a target="_blank" href="https://blog.csdn.net/HUSTHY"><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_husthy" username="HUSTHY" alt="HUSTHY" class="avatar"></a>        <div class="right-box reply-box">          <div class="new-info-box clearfix">            <a target="_blank" href="https://blog.csdn.net/HUSTHY"><span class="name mr-8">colourmind<img class="is_bloger" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/bloger@2x.png"></span></a><span class="text">回复</span><span class="colon">:</span><span class="text"></span><span class="new-comment">谢谢</span><span class="date" title="2020-06-03 09:37:35">6月前</span><span class="new-opt-floating"><a class="btn-bt  btn-reply" data-type="reply" data-flag="true">回复</a><a class="btn-bt  btn-report"><img class="btn-report-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentMore.png" title=""><span data-type="report" class="hide-report">举报</span></a></span></div><div class="comment-like " data-commentid="12427339"><img class="comment-like-img unclickImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentUnHeart.png" title="点赞"><img class="comment-like-img comment-like-img-hover" style="display:none" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><img class="comment-like-img clickedImg" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/commentActiveHeart.png" title="点赞"><span></span></div></div></div></li></ul></li></ul></div>
		<div id="commentPage" class="pagination-box d-none" style="display: block;"><div id="Paging_08733466174494247" class="ui-paging-container"><ul><li class="js-page-first js-page-action ui-pager ui-pager-disabled"></li><li class="js-page-prev js-page-action ui-pager ui-pager-disabled">&lt;</li><li data-page="1" class="ui-pager focus">1</li><li class="js-page-next js-page-action ui-pager ui-pager-disabled">&gt;</li><li class="js-page-last js-page-action ui-pager ui-pager-disabled"></li></ul></div></div>
		<div class="opt-box text-center">
			<div class="btn btn-sm btn-link-blue" id="btnMoreComment"><span>登录 查看 10 条热评</span><img class="look-more-comment" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/arrowDownComment.png"></div>
		</div>
	</div>
</div>            <div class="recommend-box insert-baidu-box">

<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/u011984148/article/details/103296212" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\&quot;}&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;BlogCommendFromBaidu&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/u011984148/article/details/103296212&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/u011984148/article/details/103296212" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\&quot;}&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;BlogCommendFromBaidu&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/u011984148/article/details/103296212&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control">
					初次<em>BERT</em>使用者的可视化指南
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/u011984148" target="_blank"><span class="blog-title">AI公园</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">11-28</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					699
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/u011984148/article/details/103296212" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control\&quot;}&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;BlogCommendFromBaidu&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/u011984148/article/details/103296212&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control">
				<div class="desc ellipsis-online ellipsis-online-1">点击上方“AI公园”，关注公众号，选择加“星标“或“置顶”作者：Jay Alammar编译：ronghuaiyang在过去几年里，处理语言的机器学习<em>模型</em>的进展一直在迅速加...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/junior_programmer/article/details/106306137" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control\&quot;}&quot;,&quot;index&quot;:&quot;3&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/junior_programmer/article/details/106306137&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/junior_programmer/article/details/106306137" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control\&quot;}&quot;,&quot;index&quot;:&quot;3&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/junior_programmer/article/details/106306137&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control">
					<em>transformers</em> 使用<em>bert</em><em>中</em>文<em>模型</em>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/junior_programmer" target="_blank"><span class="blog-title">junior_programmer的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">05-23</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					2386
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/junior_programmer/article/details/106306137" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control\&quot;}&quot;,&quot;index&quot;:&quot;3&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/junior_programmer/article/details/106306137&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control">
				<div class="desc ellipsis-online ellipsis-online-1">pytorch 下载


gpu版
pip install torch===1.5.0 torchvision===0.6.0 -f https://download.pytorch.org/whl/torch_stable.html
cpu版
pip install torch==1.5.0+cpu torchvision==0.6.0+cpu -f https://download.pytorch.org/whl/torch_stable.html

<em>中</em>文<em>bert</em>-wwm <em>模型</em> 下载

<em>中</em>文<em>bert</em>-w</div>
			</a>
		</div>
	</div>
</div>
		<div id="recommend-item-box-tow" class="recommend-item-box type_blog clearfix">
			<div id="kp_box_59" data-pid="59"><script type="text/javascript">
    (function() {
        var s = "_" + Math.random().toString(36).slice(2);
        document.write('<div style="" id="' + s + '"></div>');
        (window.slotbydup = window.slotbydup || []).push({
            id: "u3491668",
            container:  s
        });
    })();
</script><div style="" id="_bsa0dmbvtwj"><iframe id="iframeu3491668_0" name="iframeu3491668_0" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/bchm.html" width="712" height="58" align="center,center" vspace="0" hspace="0" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" style="border:0;margin:0;width:712px;height:58px" allowtransparency="true"></iframe></div>
<!-- 多条广告如下脚本只需引入一次 -->
<script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/c.js.下載" async="async" defer="defer"></script><img class="pre-img-lasy" data-src="https://kunyu.csdn.net/1.png?p=59&amp;a=78&amp;c=0&amp;k=&amp;spm=1001.2101.3001.5003&amp;d=1&amp;t=3&amp;u=8d5f08b4c3f447aa9b23f003c94bb4da" style="display: block;width: 0px;height: 0px;"></div>
		</div><div class="recommend-item-box baiduSearch clearfix" data-report-view="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-2\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_42004289/article/details/105816768&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;2&quot;}" data-flg="true">	                <div class="content-box">		                <div class="content-blog display-flex">			                  <div class="title-box">				                  <a href="https://blog.csdn.net/qq_42004289/article/details/105816768" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-2\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_42004289/article/details/105816768&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;2&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-2&amp;spm=1001.2101.3001.4242">					                <div class="tit ellipsis-online ellipsis-online-1"><em>bert</em><em>模型</em><em>源码</em>详细解读_boss的博客</div>				                  </a>			                  </div>                    <div class="info-box display-flex">                      <div class="info display-flex">                        <span class="info-block">12-16</span>                      </div>                    </div>                  </div>                  <div class="desc-box">                    <a href="https://blog.csdn.net/qq_42004289/article/details/105816768" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-2\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_42004289/article/details/105816768&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;2&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-2&amp;spm=1001.2101.3001.4242">                      <div class="desc ellipsis-online ellipsis-online-1">二. <em>bert</em><em>模型</em>的输入: 1.config : <em>bert</em>预训练<em>模型</em>的配置文件路径 2. input_ids :[batch_size,max_seq_length] 3. input_mask: 是否有掩码 [batch_size, se...</div>                    </a>                  </div>                </div>              </div><div class="recommend-item-box baiduSearch clearfix" data-report-view="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-3\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/a553181867/article/details/105389757/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;3&quot;}" data-flg="true">	                <div class="content-box">		                <div class="content-blog display-flex">			                  <div class="title-box">				                  <a href="https://blog.csdn.net/a553181867/article/details/105389757/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-3\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/a553181867/article/details/105389757/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;3&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-3&amp;spm=1001.2101.3001.4242">					                <div class="tit ellipsis-online ellipsis-online-1">基于<em>Transformers</em>库的<em>BERT</em><em>模型</em>:一个文本情感<em>分类</em>的实例...</div>				                  </a>			                  </div>                    <div class="info-box display-flex">                      <div class="info display-flex">                        <span class="info-block">12-15</span>                      </div>                    </div>                  </div>                  <div class="desc-box">                    <a href="https://blog.csdn.net/a553181867/article/details/105389757/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-3\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/a553181867/article/details/105389757/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;3&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-3&amp;spm=1001.2101.3001.4242">                      <div class="desc ellipsis-online ellipsis-online-1"><em>简介</em> 本文来讲述<em>BERT</em>应用的一个例子,采用预训练好的<em>BERT</em><em>模型</em>来进行演示。<em>BERT</em>的库来源于<em>Transformers</em>,这是一个由PyTorch编写的库,其集成了多个NLP领域SOTA的<em>模型</em>,...</div>                    </a>                  </div>                </div>              </div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/xxl98330/article/details/86704597" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control\&quot;}&quot;,&quot;index&quot;:&quot;4&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/xxl98330/article/details/86704597&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/xxl98330/article/details/86704597" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control\&quot;}&quot;,&quot;index&quot;:&quot;4&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/xxl98330/article/details/86704597&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control">
					google <em>bert</em><em>模型</em>详解 <em>源码</em>解析
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/xxl98330" target="_blank"><span class="blog-title"></span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">01-30</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					2226
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/xxl98330/article/details/86704597" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control\&quot;}&quot;,&quot;index&quot;:&quot;4&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/xxl98330/article/details/86704597&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control">
				<div class="desc ellipsis-online ellipsis-online-1">Table of Contents

<em>模型</em><em>简介</em>

1.A High-Level Look

2.Encoder(http://jalammar.github.io/illustrated-transformer/)

3.Self-Attention(http://jalammar.github.io/illustrated-transformer/)

4. Matrix Calculat...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/weixin_37479258/article/details/95987244" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control\&quot;}&quot;,&quot;index&quot;:&quot;5&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_37479258/article/details/95987244&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/weixin_37479258/article/details/95987244" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control\&quot;}&quot;,&quot;index&quot;:&quot;5&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_37479258/article/details/95987244&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control">
					<em>bert</em><em>中</em>文文本情感<em>分类</em> 微博评论挖掘之<em>Bert</em><em>实战</em>应用案例-文本情感<em>分类</em>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/weixin_37479258" target="_blank"><span class="blog-title">AI工匠Book</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">07-15</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					5329
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/weixin_37479258/article/details/95987244" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control\&quot;}&quot;,&quot;index&quot;:&quot;5&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_37479258/article/details/95987244&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control">
				<div class="desc ellipsis-online ellipsis-online-1"><em>Bert</em><em>模型</em>全称Bidirectional Encoder Representations from <em>Transformers</em>，主要分为两个部分：1训练语言<em>模型</em>（language model）的预训练（pretrain）部分，2训练具体<em>任务</em>(task)的fine-tune部分。<em>Bert</em>在NLP领域横扫了11项<em>任务</em>的最优结果，可以说是现今最近NLP<em>中</em>最重要的突破。
 相比较之前的Word Emb...</div>
			</a>
		</div>
	</div>
</div><div class="recommend-item-box baiduSearch clearfix" data-report-view="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-6\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/88548752&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;6&quot;}" data-flg="true">	                <div class="content-box">		                <div class="content-blog display-flex">			                  <div class="title-box">				                  <a href="https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/88548752" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-6\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/88548752&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;6&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-6&amp;spm=1001.2101.3001.4242">					                <div class="tit ellipsis-online ellipsis-online-1">手把手教 | 使用<em>Bert</em>预训练<em>模型</em>文本<em>分类</em>(内附<em>源码</em>)_数...</div>				                  </a>			                  </div>                    <div class="info-box display-flex">                      <div class="info display-flex">                        <span class="info-block">12-10</span>                      </div>                    </div>                  </div>                  <div class="desc-box">                    <a href="https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/88548752" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-6\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/tMb8Z9Vdm66wH68VX1/article/details/88548752&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;6&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-6&amp;spm=1001.2101.3001.4242">                      <div class="desc ellipsis-online ellipsis-online-1">Google提供了多种预训练好的<em>bert</em><em>模型</em>,有针对不同语言的和不同<em>模型</em>大小的。对于<em>中</em>文<em>模型</em>,我们使用[<em>Bert</em>-Base, Chinese](https://storage.googleapis.com/<em>bert</em>_model...</div>                    </a>                  </div>                </div>              </div><div class="recommend-item-box baiduSearch clearfix" data-report-view="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-7\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/gg7894125/article/details/106884858/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;7&quot;}" data-flg="true">	                <div class="content-box">		                <div class="content-blog display-flex">			                  <div class="title-box">				                  <a href="https://blog.csdn.net/gg7894125/article/details/106884858/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-7\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/gg7894125/article/details/106884858/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;7&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-7&amp;spm=1001.2101.3001.4242">					                <div class="tit ellipsis-online ellipsis-online-1">超详细<em>BERT</em>介绍(一)<em>BERT</em>主<em>模型</em>的结构及其组件_gg789412...</div>				                  </a>			                  </div>                    <div class="info-box display-flex">                      <div class="info display-flex">                        <span class="info-block">10-29</span>                      </div>                    </div>                  </div>                  <div class="desc-box">                    <a href="https://blog.csdn.net/gg7894125/article/details/106884858/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-7\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/gg7894125/article/details/106884858/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;7&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-7&amp;spm=1001.2101.3001.4242">                      <div class="desc ellipsis-online ellipsis-online-1"><em>BERT</em>(Bidirectional Encoder Representations from <em>Transformers</em>)是谷歌在2018年10月推出的深度语言表示<em>模型</em>。一经推出便席卷整个NLP领域,带来了革命性的进步。从此,无数...</div>                    </a>                  </div>                </div>              </div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/IT_xiao_bai/article/details/97304569" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control\&quot;}&quot;,&quot;index&quot;:&quot;6&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/IT_xiao_bai/article/details/97304569&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/IT_xiao_bai/article/details/97304569" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control\&quot;}&quot;,&quot;index&quot;:&quot;6&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/IT_xiao_bai/article/details/97304569&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control">
					<em>BERT</em>文本<em>分类</em><em>实战</em>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/IT_xiao_bai" target="_blank"><span class="blog-title">IT_xiao_bai的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">07-25</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					6224
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/IT_xiao_bai/article/details/97304569" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control\&quot;}&quot;,&quot;index&quot;:&quot;6&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/IT_xiao_bai/article/details/97304569&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control">
				<div class="desc ellipsis-online ellipsis-online-1">本文介绍了基于<em>Bert</em>对文本<em>分类</em><em>任务</em>进行了Fine-tune，详细介绍了如何使用<em>bert</em>对文本进行训练，完成了文本<em>分类</em><em>任务</em>，从训练到预测的全教程。欢迎转载，转载请注明出处。</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://medlen.blog.csdn.net/article/details/110535583" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-7.control\&quot;}&quot;,&quot;index&quot;:&quot;7&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://medlen.blog.csdn.net/article/details/110535583&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://medlen.blog.csdn.net/article/details/110535583" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-7.control\&quot;}&quot;,&quot;index&quot;:&quot;7&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://medlen.blog.csdn.net/article/details/110535583&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-7.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-7.control">
					如何下载和在本地使用<em>Bert</em>预训练<em>模型</em>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/weixin_38481963" target="_blank"><span class="blog-title">Medlen</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">12-03</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					148
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://medlen.blog.csdn.net/article/details/110535583" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-7.control\&quot;}&quot;,&quot;index&quot;:&quot;7&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://medlen.blog.csdn.net/article/details/110535583&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-7.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-7.control">
				<div class="desc ellipsis-online ellipsis-online-1"><em>bert</em> 预训练<em>模型</em>的下载有许多方式，比如从github官网上下载（官网下载的是tensorflow版本的），还可以从<em>源码</em><em>中</em>找到下载链接，然后手动下载，最后还可以从huggingface<em>中</em>下载。
关于huggingface的介绍可以看这个：Huggingface<em>简介</em>及<em>BERT</em>代码浅析
从huggingface下载预训练<em>模型</em>的地址：https://huggingface.co/models
点进去是这样的：

如果你想使用 <em>bert</em>-base-uncased 那么第一个就是，如果想使用别的预训练<em>模型</em>，还可以在</div>
			</a>
		</div>
	</div>
</div><div class="recommend-item-box baiduSearch clearfix" data-report-view="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-10\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/fengdu78/article/details/104470908/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;10&quot;}" data-flg="true">	                <div class="content-box">		                <div class="content-blog display-flex">			                  <div class="title-box">				                  <a href="https://blog.csdn.net/fengdu78/article/details/104470908/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-10\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/fengdu78/article/details/104470908/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;10&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-10&amp;spm=1001.2101.3001.4242">					                <div class="tit ellipsis-online ellipsis-online-1">一文看懂Transformer到<em>BERT</em><em>模型</em>_fengdu78的博客</div>				                  </a>			                  </div>                    <div class="info-box display-flex">                      <div class="info display-flex">                        <span class="info-block">10-29</span>                      </div>                    </div>                  </div>                  <div class="desc-box">                    <a href="https://blog.csdn.net/fengdu78/article/details/104470908/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-10\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/fengdu78/article/details/104470908/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;10&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-10&amp;spm=1001.2101.3001.4242">                      <div class="desc ellipsis-online ellipsis-online-1">3. <em>BERT</em><em>模型</em>详解 3.1 <em>BERT</em><em>简介</em> Bidirection:<em>BERT</em>的整个<em>模型</em>结构和ELMo类似,都是双向的。 Encoder:是一种编码器,<em>BERT</em>只是用到了Transformer的Encoder部分。 </div>                    </a>                  </div>                </div>              </div><div class="recommend-item-box baiduSearch clearfix" data-report-view="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-11\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/u013510838/article/details/106908787/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;11&quot;}" data-flg="true">	                <div class="content-box">		                <div class="content-blog display-flex">			                  <div class="title-box">				                  <a href="https://blog.csdn.net/u013510838/article/details/106908787/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-11\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/u013510838/article/details/106908787/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;11&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-11&amp;spm=1001.2101.3001.4242">					                <div class="tit ellipsis-online ellipsis-online-1">NLP预训练<em>模型</em>2 -- <em>BERT</em>详解和<em>源码</em>分析_谢杨易的博客</div>				                  </a>			                  </div>                    <div class="info-box display-flex">                      <div class="info display-flex">                        <span class="info-block">11-14</span>                      </div>                    </div>                  </div>                  <div class="desc-box">                    <a href="https://blog.csdn.net/u013510838/article/details/106908787/" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-11\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/u013510838/article/details/106908787/&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;11&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-11&amp;spm=1001.2101.3001.4242">                      <div class="desc ellipsis-online ellipsis-online-1">git地址https://github.com/huggingface/<em>transformers</em>。<em>bert</em><em>源码</em>放在src/<em>transformers</em>/modeling_<em>bert</em>.py<em>中</em>,入口类为<em>Bert</em>Model。 2.1 入口和总体架构...</div>                    </a>                  </div>                </div>              </div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/m0_37531129/article/details/102155091" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-8.control\&quot;}&quot;,&quot;index&quot;:&quot;8&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/m0_37531129/article/details/102155091&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/m0_37531129/article/details/102155091" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-8.control\&quot;}&quot;,&quot;index&quot;:&quot;8&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/m0_37531129/article/details/102155091&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-8.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-8.control">
					基于<em>transformers</em> <em>BERT</em>预训练<em>模型</em>问答系统(农行知道)
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/m0_37531129" target="_blank"><span class="blog-title">m0_37531129的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">10-05</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					3294
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/m0_37531129/article/details/102155091" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-8.control\&quot;}&quot;,&quot;index&quot;:&quot;8&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/m0_37531129/article/details/102155091&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-8.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-8.control">
				<div class="desc ellipsis-online ellipsis-online-1">该项目是基于 hunggingface <em>transformers</em> <em>Bert</em>SequenceClassification <em>模型</em>, 使用<em>中</em>文预训练<em>模型</em>,进行训练.
<em>模型</em>使用和结果

<em>BERT</em> <em>中</em>文预训练<em>模型</em>可以从百度云盘下载
<em>模型</em>运行命令:
<em>模型</em>运行结果:
3.1  Training dataset loss 和 acc等指标的表现
3.2 evaluation dataset  acc等指标的表现
...</div>
			</a>
		</div>
	</div>
</div>
<div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/Yolo_C/article/details/106623840" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-9.control\&quot;}&quot;,&quot;index&quot;:&quot;9&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/Yolo_C/article/details/106623840&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://blog.csdn.net/Yolo_C/article/details/106623840" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-9.control\&quot;}&quot;,&quot;index&quot;:&quot;9&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/Yolo_C/article/details/106623840&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-9.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-9.control">
					<em>Transformers</em>:如何使用<em>bert</em><em>模型</em>预留的[unused*]
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/Yolo_C" target="_blank"><span class="blog-title">Yolo_C的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">06-08</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					708
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://blog.csdn.net/Yolo_C/article/details/106623840" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-9.control\&quot;}&quot;,&quot;index&quot;:&quot;9&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/Yolo_C/article/details/106623840&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-9.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-9.control">
				<div class="desc ellipsis-online ellipsis-online-1">该链接https://www.zhihu.com/question/387534279<em>中</em>提到，可以直接使用<em>bert</em><em>模型</em>预留的[unused*]加入下游<em>任务</em>的先验知识，将[unused*]直接替换成新的token。
本文主要介绍如何直接使用<em>transformers</em>这个库实现这一功能
首先将"vocab.txt"<em>中</em>的[unused*]替换成需要的token，如[line=*]
但是如果直接调用transformer<em>中</em>的tokenizer：
tokenizer = <em>Bert</em>Tokenizer.from_pretr</div>
			</a>
		</div>
	</div>
</div><div class="recommend-item-box baiduSearch clearfix" data-report-view="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-14\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_38857272/article/details/108227059&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;14&quot;}" data-flg="true">	                <div class="content-box">		                <div class="content-blog display-flex">			                  <div class="title-box">				                  <a href="https://blog.csdn.net/qq_38857272/article/details/108227059" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-14\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_38857272/article/details/108227059&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;14&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-14&amp;spm=1001.2101.3001.4242">					                <div class="tit ellipsis-online ellipsis-online-1">...<em>transformers</em>实现一个<em>bert</em><em>分类</em><em>模型</em>(第一篇)_thinkin...</div>				                  </a>			                  </div>                    <div class="info-box display-flex">                      <div class="info display-flex">                        <span class="info-block">12-10</span>                      </div>                    </div>                  </div>                  <div class="desc-box">                    <a href="https://blog.csdn.net/qq_38857272/article/details/108227059" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-baidujs_title-14\&quot;}&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4242&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_38857272/article/details/108227059&quot;,&quot;strategy&quot;:&quot;baidujs_title&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;index&quot;:&quot;14&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-14&amp;spm=1001.2101.3001.4242">                      <div class="desc ellipsis-online ellipsis-online-1">这是这个系列的第一篇,我将在这里面介绍一下比赛开始是我们对数据的分析,并用pytorch的<em>transformers</em>框架搭建一个baseline<em>分类</em><em>模型</em>。 比赛<em>简介</em>...</div>                    </a>                  </div>                </div>              </div>
<div class="recommend-item-box type_blog clearfix" data-url="https://duanzhihua.blog.csdn.net/article/details/104285206" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-10.control\&quot;}&quot;,&quot;index&quot;:&quot;10&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://duanzhihua.blog.csdn.net/article/details/104285206&quot;}">
	<div class="content-box">
		<div class="content-blog display-flex">
			<div class="title-box">
				<a href="https://duanzhihua.blog.csdn.net/article/details/104285206" class="tit ellipsis-online ellipsis-online-1" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-10.control\&quot;}&quot;,&quot;index&quot;:&quot;10&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://duanzhihua.blog.csdn.net/article/details/104285206&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-10.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-10.control">
					Pytorch+Google <em>BERT</em><em>模型</em>（Ro<em>BERT</em>a+LSTM+GRU）<em>实战</em>
				</a>
			</div>
			<div class="info-box display-flex">
				<div class="info">
					<a href="https://blog.csdn.net/duan_zhihua" target="_blank"><span class="blog-title">段智华的博客</span></a>
				</div>
				<div class="info display-flex">
					<span class="info-block time">02-13</span>
					<span class="info-block read"><img class="read-img" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					2809
					</span>
				</div>
			</div>
		</div>
		<div class="desc-box">
			<a href="https://duanzhihua.blog.csdn.net/article/details/104285206" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-OPENSEARCH-10.control\&quot;}&quot;,&quot;index&quot;:&quot;10&quot;,&quot;strategy&quot;:&quot;OPENSEARCH&quot;,&quot;dest&quot;:&quot;https://duanzhihua.blog.csdn.net/article/details/104285206&quot;}" data-report-query="utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-10.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-10.control">
				<div class="desc ellipsis-online ellipsis-online-1">Pytorch+Google <em>BERT</em><em>模型</em>（Ro<em>BERT</em>a+LSTM+GRU）<em>实战</em>

<em>BERT</em>(Bidirectional Encoder Representations from <em>Transformers</em>)<em>模型</em>的前置基础知识，读者可以参阅以下的文章：

Pytorch使用Google <em>BERT</em><em>模型</em>进行<em>中</em>文文本<em>分类</em>（https://blog.csdn.net/duan_zhihua/article...</div>
			</a>
		</div>
	</div>
</div>
            </div>
            <div class="template-box">
                <span>©️2020 CSDN</span>
                <span>皮肤主题: 大白</span>
                <span> 设计师:CSDN官方博客</span>
                <span>
                    <a href="https://blog.csdn.net/" class="back-home c-blue c-blue-hover c-blue-focus">返回首页</a>
                </span>
            </div>
<div class="blog-footer-bottom" style="margin-top:10px;">
        <div id="copyright-box" class="">
          <div id="csdn-copyright-footer" class="column small">
            <ul class="footer-column-t">
            <li>
              <a href="https://www.csdn.net/company/index.html#about" target="_blank">关于我们</a>
            </li>
            <li>
              <a href="https://www.csdn.net/company/index.html#recruit" target="_blank">招贤纳士</a>
            </li>
            <li>
              <a href="https://www.csdn.net/company/index.html#advertisement" target="_blank">广告服务</a>
            </li>
            <li>
              <a href="https://plugin.csdn.net/" target="_blank">开发助手</a>
            </li>
            <li>
              <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/tel.png" alt="">
              <span>400-660-0108</span>
            </li>
            <li>
              <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/email.png" alt="">
              <a href="mailto:webmaster@csdn.net" target="_blank">kefu@csdn.net</a>
            </li>
            <li>
              <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/cs.png" alt="">
              <a href="https://csdn.s2.udesk.cn/im_client/?web_plugin_id=29181" target="_blank">在线客服</a>
            </li>
            <li>
              工作时间&nbsp;8:30-22:00
            </li>
          </ul>
            <ul class="footer-column-b">
            <li><img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/badge.png" alt=""><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502030143" rel="noreferrer" target="_blank">公安备案号11010502030143</a></li>
            <li><a href="http://beian.miit.gov.cn/publish/query/indexFirst.action" rel="noreferrer" target="_blank">京ICP备19004658号</a></li>
            <li><a href="https://csdnimg.cn/release/live_fe/culture_license.png" rel="noreferrer" target="_blank">京网文〔2020〕1039-165号</a></li>
            <li><a href="https://csdnimg.cn/cdn/content-toolbar/csdn-ICP.png" target="_blank">经营性网站备案信息</a></li>
            <li><a href="http://www.bjjubao.org/" target="_blank">北京互联网违法和不良信息举报中心</a></li>
            <li><a href="http://www.cyberpolice.cn/" target="_blank">网络110报警服务</a></li>
            <li><a href="http://www.12377.cn/" target="_blank">中国互联网举报中心</a></li>
            <li><a href="https://download.csdn.net/index.php/tutelage/" target="_blank">家长监护</a></li>
            <li><a href="https://chrome.google.com/webstore/detail/csdn%E5%BC%80%E5%8F%91%E8%80%85%E5%8A%A9%E6%89%8B/kfkdboecolemdjodhmhmcibjocfopejo?hl=zh-CN" target="_blank">Chrome商店下载</a></li>
            <li>©1999-2020北京创新乐知网络技术有限公司</li>
            <li><a href="https://www.csdn.net/company/index.html#statement" target="_blank">版权与免责声明</a></li>
            <li><a href="https://blog.csdn.net/blogdevteam/article/details/90369522" target="_blank">版权申诉</a></li>
          </ul>
          </div>
        </div>
      </div>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/csdn-footer.js.下載" data-isfootertrack="false" type="text/javascript"></script>
<script type="text/javascript">
    window.csdn.csdnFooter.options = {
        el: '.blog-footer-bottom',
        type: 2
    }
</script>        </main>
<aside class="blog_container_aside" style="position: fixed; bottom: 0px; z-index: 99; left: 80px; width: 300px; top: auto;">
    <div id="asideProfile" class="aside-box">
    <div class="profile-intro d-flex">
        <div class="avatar-box d-flex justify-content-center flex-column">
            <a href="https://blog.csdn.net/HUSTHY" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4121&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY&quot;,&quot;ab&quot;:&quot;new&quot;}">
                <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/3_husthy" class="avatar_pic">
            </a>
        </div>
        <div class="user-info d-flex flex-column profile-intro-name-box">
            <div class="profile-intro-name-boxTop">
                <a href="https://blog.csdn.net/HUSTHY" class="" id="uid" title="colourmind" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4122&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <span class="name " username="HUSTHY">colourmind</span>
                </a>
                <span>
                </span>
                <span class="flag expert-blog">
                <span class="bubble">CSDN认证博客专家</span>
                </span>
                <span class="flag company-blog">
                <span class="bubble">CSDN认证企业博客</span>
                </span>
            </div>
            <div class="profile-intro-name-boxFooter">
                <span class="personal-home-page personal-home-years">码龄9年</span>
                    <span class="personal-home-page">
                    <a class="personal-home-certification" href="https://blog.csdn.net/HUSTHY?utm_source=14998968" target="_blank" title="暂无认证">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/nocErtification.png" alt="">
                    暂无认证
                    </a>
                    </span>
            </div>
        </div>
    </div>
    <div class="data-info d-flex item-tiling">
        <dl class="text-center" title="37">
            <a href="https://blog.csdn.net/HUSTHY" data-report-click="{&quot;mod&quot;:&quot;1598321000_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4310&quot;}" data-report-query="t=1">  
                <dt><span class="count">37</span></dt>
                <dd class="font">原创</dd>
            </a>
        </dl>
        <dl class="text-center" data-report-click="{&quot;mod&quot;:&quot;1598321000_002&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4311&quot;}" title="37304">
            <a href="https://blog.csdn.net/rank/writing_rank" target="_blank">
                <dt><span class="count">3万+</span></dt>
                <dd class="font">周排名</dd>
            </a>
        </dl>
        <dl class="text-center" title="88341">
            <a href="https://blog.csdn.net/rank/writing_rank_total" data-report-click="{&quot;mod&quot;:&quot;1598321000_003&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4312&quot;}" target="_blank">
                <dt><span class="count">8万+</span></dt>
                <dd class="font">总排名</dd>
            </a>
        </dl>
        <dl class="text-center" style="min-width:58px" title="63894">  
            <dt><span class="count">6万+</span></dt>
            <dd>访问</dd>
        </dl>
        <dl class="text-center" title="4级,点击查看等级说明">
            <dt><a href="https://blog.csdn.net/home/help.html#level" target="_blank">
                <img class="level" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/blog4.png">
            </a>
            </dt>
            <dd>等级</dd>
        </dl>
    </div>
    <div class="item-rank"></div>
    <div class="data-info d-flex item-tiling">
        <dl class="text-center" title="1110">
            <dt><span class="count">1110</span></dt>
            <dd>积分</dd>
        </dl>
         <dl class="text-center" id="fanBox" title="34">
            <dt><span class="count" id="fan">34</span></dt>
            <dd>粉丝</dd>
        </dl>
        <dl class="text-center" title="64">
            <dt><span class="count">64</span></dt>
            <dd>获赞</dd>
        </dl>
        <dl class="text-center" title="53">
            <dt><span class="count">53</span></dt>
            <dd>评论</dd>
        </dl>
        <dl class="text-center" title="248">
            <dt><span class="count">248</span></dt>
            <dd>收藏</dd>
        </dl>
    </div>
    <div class="aside-box-footer">
        <div class="badge-box d-flex">
            <div class="badge d-flex">
                <div class="icon-badge" title="持之以恒">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click="{&quot;spm&quot;:&quot;3001.4296&quot;}" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/chizhiyiheng@240.png" alt="持之以恒">
                    </div>
                </div>
                <div class="icon-badge" title="勤写标兵Lv2">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click="{&quot;spm&quot;:&quot;3001.4296&quot;}" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/qixiebiaobing2@240.png" alt="勤写标兵Lv2">
                    </div>
                </div>
                <div class="icon-badge" title="学习力">
                    <div class="mouse-box">
                        <img class="medal-img" data-report-click="{&quot;spm&quot;:&quot;3001.4296&quot;}" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/yuanli_xuexili@240.png" alt="学习力">
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="profile-intro-name-boxOpration">
        <div class="opt-letter-watch-box">
        <a class="bt-button personal-letter" href="https://im.csdn.net/chat/HUSTHY" target="_blank" rel="noopener">私信</a>
        </div>
        <div class="opt-letter-watch-box"> 
            <a class="personal-watch bt-button" id="btnAttent">关注</a>  
        </div>
    </div>
</div>
<div id="asideSearchArticle" class="aside-box">
	<div class="aside-content search-comter">
    <div class="aside-search aside-search-blog">         
        <input type="text" class="input-serch-blog" name="" autocomplete="off" value="" id="search-blog-words" placeholder="搜博主文章">
        <a class="btn-search-blog">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/csdn-sou.png">
        </a>
    </div>
    </div>
</div>


<div id="asideHotArticle" class="aside-box">
	<h3 class="aside-title">热门文章</h3>
	<div class="aside-content">
		<ul class="hotArticle-list">
			<li>
				<a href="https://blog.csdn.net/HUSTHY/article/details/101041825" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4139&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/101041825&quot;,&quot;ab&quot;:&quot;new&quot;}">
				python for循环多进程执行应用
					<img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					<span class="read">10804</span>
                </a>
			</li>
			<li>
				<a href="https://blog.csdn.net/HUSTHY/article/details/103164934" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4139&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/103164934&quot;,&quot;ab&quot;:&quot;new&quot;}">
				word2vec模型训练保存加载及简单使用
					<img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					<span class="read">6290</span>
                </a>
			</li>
			<li>
				<a href="https://blog.csdn.net/HUSTHY/article/details/106992678" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4139&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/106992678&quot;,&quot;ab&quot;:&quot;new&quot;}">
				P-SIF长文本表示方法
					<img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					<span class="read">5285</span>
                </a>
			</li>
			<li>
				<a href="https://blog.csdn.net/HUSTHY/article/details/100569693" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4139&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/100569693&quot;,&quot;ab&quot;:&quot;new&quot;}">
				关于Bert模型参数的分布
					<img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					<span class="read">4333</span>
                </a>
			</li>
			<li>
				<a href="https://blog.csdn.net/HUSTHY/article/details/103087691" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4139&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/103087691&quot;,&quot;ab&quot;:&quot;new&quot;}">
				python多进程中使用tqdm监控任务执行进度
					<img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/readCountWhite.png" alt="">
					<span class="read">2945</span>
                </a>
			</li>
		</ul>
	</div>
</div>
<div id="asideCategory" class="aside-box flexible-box" style="display:block!important;">
    <h3 class="aside-title">分类专栏</h3>
    <div class="aside-content">
        <ul>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9330450.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9330450.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756926.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">NLP自然语言处理</span>
                    </span>
                    <span class="count float-right">25篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9653010.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9653010.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756926.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">pytorch</span>
                    </span>
                    <span class="count float-right">16篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9570067.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9570067.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756930.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">深度学习</span>
                    </span>
                    <span class="count float-right">25篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9343942.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9343942.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756927.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">Python总结</span>
                    </span>
                    <span class="count float-right">14篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_10341016.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_10341016.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756757.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">TensorFlow</span>
                    </span>
                    <span class="count float-right">1篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9663260.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9663260.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756922.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">pandas</span>
                    </span>
                    <span class="count float-right">1篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9779571.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9779571.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756927.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">anaconda</span>
                    </span>
                    <span class="count float-right">1篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9732145.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9732145.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756925.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">迁移学习</span>
                    </span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9674500.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9674500.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756922.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">ubuntu</span>
                    </span>
                    <span class="count float-right">1篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9515279.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9515279.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756724.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">Linux</span>
                    </span>
                    <span class="count float-right">2篇</span>
                </a>
            </li>
            <li class="">
                <a class="clearfix" target="_blank" href="https://blog.csdn.net/husthy/category_9330472.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/husthy/category_9330472.html&quot;,&quot;ab&quot;:&quot;new&quot;}">
                    <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/20201014180756919.png" alt="" onerror="this.src=&#39;https://img-blog.csdnimg.cn/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64&#39;">
                    <span class="title oneline">
                        <span class="text">JAVA开发</span>
                    </span>
                    <span class="count float-right">1篇</span>
                </a>
            </li>
        </ul>
    </div>
    <p class="text-center">
        <a class="flexible-btn" data-fbox="aside-archive"><img class="look-more" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/arrowDownWhite.png" alt=""></a>
    </p>
</div>
<div id="asideNewComments" class="aside-box">
    <h3 class="aside-title">最新评论</h3>
    <div class="aside-content">
        <ul class="newcomment-list">
            <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/HUSTHY/article/details/101649012#comments_14276329" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4231&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/101649012#comments_14276329&quot;,&quot;ab&quot;:&quot;new&quot;}">pytorch中unsqueeze()、squeeze()、expand()、repeat()、view()、和cat()函数的总结</a>
                <p class="comment ellipsis">
                    <a href="https://blog.csdn.net/weixin_39175109" class="user-name" target="_blank">Criticc: </a>
                    <span class="code-comments">感谢！</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14165119" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4231&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14165119&quot;,&quot;ab&quot;:&quot;new&quot;}">pytorch原生支持的apex混合精度和nvidia apex混合精度AMP技术加速模型训练效果对比</a>
                <p class="comment ellipsis">
                    <a href="https://im0qianqian.blog.csdn.net/" class="user-name" target="_blank">小坏蛋_千千: </a>
                    <span class="code-comments">也许是模型的问题，我是加载预训练语言模型 Albert，可能中途转化为 fp16 的不多所以才有这个现象，谢谢啦~</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14109312" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4231&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14109312&quot;,&quot;ab&quot;:&quot;new&quot;}">pytorch原生支持的apex混合精度和nvidia apex混合精度AMP技术加速模型训练效果对比</a>
                <p class="comment ellipsis">
                    <a href="https://blog.csdn.net/HUSTHY" class="user-name" target="_blank">colourmind: </a>
                    <span class="code-comments">3090的实验是写在博客——https://blog.csdn.net/HUSTHY/article/details/108639514——余弦相似度计算的实现方式——这篇博客中</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14109277" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4231&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14109277&quot;,&quot;ab&quot;:&quot;new&quot;}">pytorch原生支持的apex混合精度和nvidia apex混合精度AMP技术加速模型训练效果对比</a>
                <p class="comment ellipsis">
                    <a href="https://blog.csdn.net/HUSTHY" class="user-name" target="_blank">colourmind: </a>
                    <span class="code-comments">应该是没有问题的，可能是网络模型的问题，就是模型网络计算中切换为Fp16的计算确实不多；另外也有可能是硬件问题，就是显卡不支持fp16；最近我用3090直接测试fp16和fp32的计算发现显存收益确实是在50%左右，计算速度也提高了，就是精度下降。它这个amp自动混合梯度计算具体实现的原理很负责，我也不清楚，也只能认为是有的地方把fp32自动切换为fp16了，切换多少就有多少收益。</span>
                </p>
            </li>
            <li>
                <a class="title text-truncate" target="_blank" href="https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14096901" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4231&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/109485088#comments_14096901&quot;,&quot;ab&quot;:&quot;new&quot;}">pytorch原生支持的apex混合精度和nvidia apex混合精度AMP技术加速模型训练效果对比</a>
                <p class="comment ellipsis">
                    <a href="https://im0qianqian.blog.csdn.net/" class="user-name" target="_blank">小坏蛋_千千: </a>
                    <span class="code-comments">我最近也尝试了 apex 以及 torch 自带的 amp，发现相比较不用基本显存收益不大（即使 apex 开 O3 显存也收益不大），然后效果上的确会变差。不确定怎么回事是不是正常的，预想的是能节省 30% - 40% 的显存。</span>
                </p>
            </li>
        </ul>
    </div>
</div>
<div id="asideArchive" class="aside-box">
    <h3 class="aside-title">最新文章</h3>
    <div class="aside-content">
        <ul class="inf_list clearfix">
            <li class="clearfix">
            <a href="https://blog.csdn.net/HUSTHY/article/details/108639514" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4136&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/108639514&quot;,&quot;ab&quot;:&quot;new&quot;}">余弦相似度计算的实现方式</a>
            </li>
            <li class="clearfix">
            <a href="https://blog.csdn.net/HUSTHY/article/details/109485088" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4136&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/109485088&quot;,&quot;ab&quot;:&quot;new&quot;}">pytorch原生支持的apex混合精度和nvidia apex混合精度AMP技术加速模型训练效果对比</a>
            </li>
            <li class="clearfix">
            <a href="https://blog.csdn.net/HUSTHY/article/details/109276404" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4136&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/HUSTHY/article/details/109276404&quot;,&quot;ab&quot;:&quot;new&quot;}">中文NER任务简析与深度算法模型总结和实战展示</a>
            </li>
        </ul>
        <div class="archive-bar"></div>
        <div class="archive-box">
                <div class="archive-list-item"><a href="https://blog.csdn.net/HUSTHY/article/month/2020/11" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;&quot;}"><span class="year">2020年</span><span class="num">36篇</span></a></div>
                <div class="archive-list-item"><a href="https://blog.csdn.net/HUSTHY/article/month/2019/12" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;&quot;}"><span class="year">2019年</span><span class="num">16篇</span></a></div>
                <div class="archive-list-item"><a href="https://blog.csdn.net/HUSTHY/article/month/2018/05" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;&quot;}"><span class="year">2018年</span><span class="num">1篇</span></a></div>
        </div>
    </div>
</div>
	<div id="footerRightAds" class="isShowFooterAds" style="width: 300px; height: 600px;">
		<div class="aside-box" style="width: 300px; height: 600px;">
			<div id="kp_box_57" data-pid="57" style="width: 300px; height: 600px;"><script async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/f(7).txt"></script>
<!-- PC-博客详情页-左下视窗（300*600） -->
<ins class="adsbygoogle" style="display: block; height: 600px; width: 300px;" data-ad-client="ca-pub-1076724771190722" data-ad-slot="1173711872" data-ad-format="auto" data-full-width-responsive="true" data-adsbygoogle-status="done"><ins id="aswift_0_expand" style="display:inline-table;border:none;height:600px;margin:0;padding:0;position:relative;visibility:visible;width:300px;background-color:transparent;" tabindex="0" title="Advertisement" aria-label="Advertisement"><ins id="aswift_0_anchor" style="display: block; border: none; height: 600px; margin: 0px; padding: 0px; position: relative; visibility: visible; width: 300px; background-color: transparent; overflow: hidden;"><iframe id="aswift_0" name="aswift_0" style="left:0;position:absolute;top:0;border:0;width:300px;height:600px;" sandbox="allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation" width="300" height="600" frameborder="0" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/ads.html" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" data-google-container-id="a!1" data-google-query-id="CMnoy6G24-0CFVwmlgodi8YNKw" data-load-complete="true"></iframe></ins></ins></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script><img class="pre-img-lasy" data-src="https://kunyu.csdn.net/1.png?p=57&amp;a=2488&amp;c=0&amp;k=&amp;spm=1001.2101.3001.5001&amp;d=1&amp;t=3&amp;u=2a1bae4166e941969092a03ed09918f6" style="display: block;width: 0px;height: 0px;" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/1.png"></div>
		</div>
	</div>
    <!-- 详情页显示目录 -->
<!--文章目录-->
<div id="asidedirectory" class="aside-box">
    <div class="groupfile" id="directory">
        <h3 class="aside-title">目录</h3>
        <div class="align-items-stretch group_item">
            <div class="pos-box">
            <div class="scroll-box">
                <div class="toc-box"><ol><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t0">一、bert模型简介</a></li><li class="sub-box"><ol><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t1">bert与训练的流程：</a></li><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t2">bert模型的输入</a></li></ol></li><li class="active"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t3">二、huggingface的bert源码浅析</a></li><li class="sub-box"><ol><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t4">bert提取文本词向量</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t5">BertModel代码阅读</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t6">BertEmbedding子模型</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t7">BertEncoder</a></li><li class="sub-box"><ol><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t8">BertAttention</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t9">BertIntermediate</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t10">BertOutput(config)</a></li></ol></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t11">BertPooler()</a></li></ol></li><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t12">三、Bert文本分类任务实战</a></li><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t13">四、Bert模型难点总结</a></li></ol></div>
            </div>
            </div>
        </div>
    </div>
</div>
</aside>
<script>
	$("a.flexible-btn").click(function(){
		$(this).parents('div.aside-box').removeClass('flexible-box');
		$(this).parents("p.text-center").remove();
	})
</script>
<script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/user-tooltip.js.下載"></script>
<script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/user-medal.js.下載"></script>    </div>
<div class="recommend-right  align-items-stretch clearfix" id="rightAside" data-type="recommend">
    <aside class="recommend-right_aside">
        <div id="recommend-right" style="position: fixed; top: 56px;">
                        <div class="flex-column aside-box groupfile" id="groupfile" style="display: block; max-height: 483.5px;">
                <div class="groupfile-div" style="max-height: 483.5px;">
                <h3 class="aside-title">目录</h3>
                <div class="align-items-stretch group_item">
                    <div class="pos-box">
                        <div class="scroll-box">
                            <div class="toc-box"><ol><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t0">一、bert模型简介</a></li><li class="sub-box"><ol><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t1">bert与训练的流程：</a></li><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t2">bert模型的输入</a></li></ol></li><li class="active"><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t3">二、huggingface的bert源码浅析</a></li><li class="sub-box"><ol><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t4">bert提取文本词向量</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t5">BertModel代码阅读</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t6">BertEmbedding子模型</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t7">BertEncoder</a></li><li class="sub-box"><ol><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t8">BertAttention</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t9">BertIntermediate</a></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t10">BertOutput(config)</a></li></ol></li><li><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t11">BertPooler()</a></li></ol></li><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t12">三、Bert文本分类任务实战</a></li><li class=""><a href="https://blog.csdn.net/HUSTHY/article/details/105882989#t13">四、Bert模型难点总结</a></li></ol></div>
                        </div>
                    </div>
                </div>
                </div>
            </div>
                <div id="recommendAdBox">
                    <div id="kp_box_479" data-pid="479"><script async="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/f(7).txt"></script>
<!-- PC-博客内页右侧第一顺位 -->
<ins class="adsbygoogle" style="display:inline-block;width:300px;height:600px" data-ad-client="ca-pub-1076724771190722" data-ad-slot="1827473444" data-adsbygoogle-status="done"><ins id="aswift_1_expand" style="display:inline-table;border:none;height:600px;margin:0;padding:0;position:relative;visibility:visible;width:300px;background-color:transparent;" tabindex="0" title="Advertisement" aria-label="Advertisement"><ins id="aswift_1_anchor" style="display:block;border:none;height:600px;margin:0;padding:0;position:relative;visibility:visible;width:300px;background-color:transparent;"><iframe id="aswift_1" name="aswift_1" style="left:0;position:absolute;top:0;border:0;width:300px;height:600px;" sandbox="allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation" width="300" height="600" frameborder="0" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/ads(1).html" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" data-google-container-id="a!2" data-google-query-id="COTqy6G24-0CFcNElgodRwAEKQ" data-load-complete="true"></iframe></ins></ins></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script><img class="pre-img-lasy" data-src="https://kunyu.csdn.net/1.png?p=479&amp;a=3266&amp;c=0&amp;k=&amp;spm=1001.2101.3001.4834&amp;d=1&amp;t=3&amp;u=bbd202665e904ad6ab47b45714d207f1" style="display: block;width: 0px;height: 0px;"></div>
                </div>
            <div class="recommend-list-box d-flex flex-column aside-box" id="recommend-list-box">
            <ul class="recommend-fixed-box align-items-stretch">
                <li class="right-item">
                    <a href="https://plugin.csdn.net/" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.476333.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;106_476333_RCMD&quot;,&quot;dest&quot;:&quot;https://plugin.csdn.net/&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.476333.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;106_476333_RCMD&quot;,&quot;dest&quot;:&quot;https://plugin.csdn.net/&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.476333.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.476333.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>CSDN官方插件，现在体验可获得永久免费去广告特权！</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/h___q/article/details/111587919" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-2.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/h___q/article/details/111587919&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-2.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/h___q/article/details/111587919&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-2.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-2.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>thunderbird设置outlook格式回复头</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38647822/13763256" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-3.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;3&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38647822/13763256&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-3.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;3&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38647822/13763256&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-3.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-3.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Python之批量创建文件的实例讲解</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38517892/13763231" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-4.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;4&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38517892/13763231&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-4.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;4&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38517892/13763231&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-4.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-4.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>python下MySQLdb用法实例分析</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/sensorsdata/article/details/111587930" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-5.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;5&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/sensorsdata/article/details/111587930&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-5.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;5&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/sensorsdata/article/details/111587930&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-5.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-5.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>神策数据赋能物流服务行业数字化转型</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/9910" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-6.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;6&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/9910&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-6.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;6&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/9910&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-6.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-6.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Java语言零基础系统清晰路线学习-①Java基本语法</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://fzy15116089232.blog.csdn.net/article/details/111587877" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-7.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;7&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://fzy15116089232.blog.csdn.net/article/details/111587877&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-7.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;7&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://fzy15116089232.blog.csdn.net/article/details/111587877&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-7.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-7.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Java中Double保留后小数位的几种方法</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/31499" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-8.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;8&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31499&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-8.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;8&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31499&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-8.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-8.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Qt5 Qml Virtual Keyboard Style</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38562026/13763289" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-9.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;9&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38562026/13763289&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-9.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;9&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38562026/13763289&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-9.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-9.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>2005上半年乘用车销售总结</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/nimendou4zhu/article/details/111587910" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-10.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;10&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/nimendou4zhu/article/details/111587910&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-10.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;10&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/nimendou4zhu/article/details/111587910&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-10.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-10.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>百度快排（百度下拉）刷词原理是什么？</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/qq_44954571/article/details/111587533" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-11.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;11&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_44954571/article/details/111587533&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-11.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;11&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_44954571/article/details/111587533&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-11.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-11.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>3.3双端口RAM &amp; 多模块存储器（用于提升主存速度）</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/weixin_44325613/article/details/111587625" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-12.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;12&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_44325613/article/details/111587625&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-12.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;12&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_44325613/article/details/111587625&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-12.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-12.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>css3艺术—(一)【圆形、椭圆、字母i】</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38661128/13763224" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-13.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;13&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38661128/13763224&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-13.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;13&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38661128/13763224&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-13.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-13.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>口蹄疫的防治</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/qq_44647223/article/details/111587294" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-14.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;14&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_44647223/article/details/111587294&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-14.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;14&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_44647223/article/details/111587294&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-14.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-14.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>操作系统  请求分页管理（续）</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38734269/13763213" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-15.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;15&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38734269/13763213&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-15.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;15&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38734269/13763213&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-15.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-15.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>金字塔顶的诱惑DOC</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38681628/13763276" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-16.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;16&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38681628/13763276&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-16.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;16&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38681628/13763276&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-16.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-16.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>中药行业投资报告</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/31486" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-17.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;17&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31486&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-17.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;17&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31486&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-17.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-17.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>轻松掌握数据分析与可视化技术</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/weixin_49427084/article/details/111587813" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-18.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;18&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_49427084/article/details/111587813&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-18.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;18&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_49427084/article/details/111587813&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-18.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-18.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Layui选项卡</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/weixin_39328406/article/details/111587955" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-19.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;19&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_39328406/article/details/111587955&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-19.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;19&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_39328406/article/details/111587955&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-19.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-19.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>常见版本控制系统（CVS、SVN、BitKeeper、Git 等）基础知识</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38666230/13763264" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-20.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;20&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38666230/13763264&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-20.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;20&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38666230/13763264&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-20.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-20.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>国际金融分析报告（下）</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/weixin_49843717/article/details/111587862" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-21.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;21&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_49843717/article/details/111587862&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-21.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;21&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_49843717/article/details/111587862&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-21.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-21.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>SSLOJ2324 细胞问题&amp;P1451</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/31517" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-22.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;22&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31517&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-22.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;22&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31517&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-22.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-22.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>定制企业级的linux系统</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/MinskyYi/article/details/111587863" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-23.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;23&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/MinskyYi/article/details/111587863&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-23.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;23&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/MinskyYi/article/details/111587863&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-23.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-23.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>20201222_146_模块导入_import 和 from_import 语句详解和区别</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38631225/13763220" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-24.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;24&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38631225/13763220&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-24.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;24&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38631225/13763220&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-24.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-24.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>NY5172-2002 无公害食品 水发水产品</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/qq_34062754/article/details/111584290" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-25.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;25&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_34062754/article/details/111584290&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-25.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;25&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_34062754/article/details/111584290&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-25.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-25.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>排序算法之冒泡排序</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/cllove_/13763277" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-26.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;26&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/cllove_/13763277&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-26.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;26&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/cllove_/13763277&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-26.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-26.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>PingFangSC、苹方字体下载</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/tuliyou/article/details/111587793" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-27.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;27&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/tuliyou/article/details/111587793&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-27.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;27&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/tuliyou/article/details/111587793&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-27.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-27.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Python类方法的重写</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38582716/13763290" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-28.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;28&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38582716/13763290&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-28.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;28&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38582716/13763290&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-28.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-28.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>详谈Python3 操作系统与路径 模块(os / os.path / pathlib)</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/31509" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-29.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;29&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31509&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-29.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;29&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31509&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-29.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-29.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>青少年编程等级考试-Scratch图形化3级</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38628612/13763292" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-30.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;30&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38628612/13763292&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-30.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;30&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38628612/13763292&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-30.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-30.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Python实现随机生成手机号及正则验证手机号的方法</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/m0_51794965/article/details/111587771" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-31.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;31&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/m0_51794965/article/details/111587771&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-31.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;31&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/m0_51794965/article/details/111587771&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-31.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-31.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>矩阵快速幂（可以起到优化dp动态规划的作用）</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/31493" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-32.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;32&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31493&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-32.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;32&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31493&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-32.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-32.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>单路由器多线路接入运营商冗余实战</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38713996/13763281" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-33.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;33&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38713996/13763281&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-33.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;33&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38713996/13763281&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-33.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-33.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>详谈套接字中SO_REUSEPORT和SO_REUSEADDR的区别</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/combo/detail/1974" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-34.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;34&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/combo/detail/1974&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-34.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;34&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/combo/detail/1974&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-34.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-34.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>Drools规则引擎套餐</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://download.csdn.net/download/weixin_38575421/13763240" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-35.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;35&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38575421/13763240&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-download-alirec-35.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;35&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://download.csdn.net/download/weixin_38575421/13763240&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-download-alirec-35.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-download-alirec-35.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>饲料添加剂使用的范围与层次</h5>
                            </div>
                            <span class="download_mark_button ">立即下载 </span>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/bundled/detail/312" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-36.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;36&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/bundled/detail/312&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-36.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;36&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/bundled/detail/312&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-36.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-36.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>程序员学院APP【吐槽者联盟】礼包</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/31529" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-37.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;37&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31529&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-37.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;37&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31529&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-37.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-37.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>【数据分析实战训练营】SPSS调查问卷统计分析</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://edu.csdn.net/course/detail/31530" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-38.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;38&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31530&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-38.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;38&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://edu.csdn.net/course/detail/31530&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-38.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-edu_course-alirec-38.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>【数据分析实战训练营】机器学习模型及应用</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://jianhongwei1989.blog.csdn.net/article/details/111587858" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-39.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;39&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://jianhongwei1989.blog.csdn.net/article/details/111587858&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-39.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;39&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://jianhongwei1989.blog.csdn.net/article/details/111587858&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-39.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-39.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>三坐标测量机坐标系</h5>
                            </div>
                        </div>
                    </a>
                </li> 
                <li class="right-item">
                    <a href="https://blog.csdn.net/mnrssj/article/details/111587853" target="_blank" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-40.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;40&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/mnrssj/article/details/111587853&quot;}" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;mod&quot;:&quot;popu_858&quot;,&quot;extra&quot;:&quot;{\&quot;utm_medium\&quot;:\&quot;distribute.pc_blog_right_sidebar.none-task-blog-alirec-40.nonecase\&quot;}&quot;,&quot;index&quot;:&quot;40&quot;,&quot;strategy&quot;:&quot;alirec&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/mnrssj/article/details/111587853&quot;}" data-report-query="utm_medium=distribute.pc_blog_right_sidebar.none-task-blog-alirec-40.nonecase&amp;depth_1-utm_source=distribute.pc_blog_right_sidebar.none-task-blog-alirec-40.nonecase">
                        <div class="context-box ">
                            <div class="content clearfix ">
                                <h5>在Java中将AI转换为PSD，JPEG或PNG图像格式指南</h5>
                            </div>
                        </div>
                    </a>
                </li> 
            </ul>
            </div>
        </div>
    </aside>
</div>

</div>
<div class="mask-dark"></div>
<script type="text/javascript">
    var timert = setInterval(function(){
      sideToolbar = $(".csdn-side-toolbar");
      if (sideToolbar.length > 0) {
        sideToolbar.css('cssText','bottom:64px !important;')
        clearInterval(timert);
      }
    }, 200);
</script>
<script>
    var articleId = 105882989;
    var commentscount = 10;
    var curentUrl = "https://blog.csdn.net/HUSTHY/article/details/105882989";
    var myUrl = "https://my.csdn.net/";
    var highlight = ["bert","模型","简介","transformers","中","bert","模型","源码","阅读","分类","任务","实战","难点","总结"];//高亮数组
    var share_card_url = "https://blog.csdn.net/HUSTHY/article/shareArticleCardPage?article_id=105882989"
	var articleType = 1;
    var baiduKey = "bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结";
    var needInsertBaidu = true;
    var recommendRegularDomainArr = ["blog.csdn.net/.+/article/details/","download.csdn.net/download/","edu.csdn.net/course/detail/","ask.csdn.net/questions/","bbs.csdn.net/topics/","www.csdn.net/gather_.+/"]
    var codeStyle = "atom-one-dark";
    var baiduSearchType = "title";
    var canRead = true;
    var blogMoveHomeArticle = false;
    var showPcWindowAd = false;
    var linkPage = true;
</script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/sandalstrap.min.js.下載"></script>
<div class="skin-boxshadow"></div>
<div style="display:none;">
	<img src="https://blog.csdn.net/HUSTHY/article/details/105882989" onerror="setTimeout(function(){if(!/(csdn.net|iteye.com|baiducontent.com|googleusercontent.com|360webcache.com|sogoucdn.com|bingj.com|baidu.com)$/.test(window.location.hostname)){window.location.href=&quot;\x68\x74\x74\x70\x73\x3a\x2f\x2f\x77\x77\x77\x2e\x63\x73\x64\x6e\x2e\x6e\x65\x74&quot;}},3000);">
</div>

    <!-- 富文本柱状图  -->
	<link rel="stylesheet" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/chart.css">
	<script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/chart.min.js.下載"></script>
    <script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/widget2chart.js.下載"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/pc_wap_highlight-db1e81323a.min.js.下載" type="text/javascript"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/pc_wap_common-906586e915.min.js.下載" type="text/javascript"></script>
<link rel="stylesheet" href="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/atom-one-dark.css">
<script>
 // 全局声明
 if (window.csdn === undefined) {
      window.csdn = {};
    }
    window.csdn.sideToolbar = {
        options: {
            report:{
                isShow: true,
            },
            qr: {
                isShow: false,
            },
            guide: {
                isShow: true
            }
        }
    }
    $(function(){
        $(document).on('click',"a.option-box[data-type='report']",function() {
            window.csdn.userLogin.loadAjax(function(res){
                showReport(false,articleTitles);
            })
        });
    })
</script>
    <script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/baidu-search.js.下載" type="text/javascript"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/qrcode.js.下載"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/common-b286f966c8.min.js.下載" type="text/javascript"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/detail-d9a4c4b737.min.js.下載" type="text/javascript"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/user-ordercart.js.下載" type="text/javascript"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/column-78261cfea6.min.js.下載" type="text/javascript"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/side-toolbar.js.下載" type="text/javascript"></script>
<script src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/copyright.js.下載" type="text/javascript"></script>
<script>
    $(".MathJax").remove();
    if ($('div.markdown_views pre.prettyprint code.hljs').length > 0) {
        $('div.markdown_views')[0].className = 'markdown_views';
    }
</script>
<script type="text/javascript" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/MathJax.js.下載"></script>
<script type="text/x-mathjax-config;executed=true">
    MathJax.Hub.Config({
            "HTML-CSS": {
                    linebreaks: { automatic: true, width: "94%container" },
                    imageFont: null
            },
            tex2jax: {
                preview: "none"
            },
            mml2jax: {
                preview: 'none'
            }
    });
</script>
<script type="text/javascript" crossorigin="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/user-login.js.下載"></script>
<script type="text/javascript" crossorigin="" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/login-box.js.下載"></script>
<div id="pointDivs"><div class="point-outer point-pre"><div class="point-inner"></div></div><div class="point-outer point-pre"><div class="point-inner"></div></div><div class="point-outer point-pre"><div class="point-inner"></div></div><div class="point-outer point-pre"><div class="point-inner"></div></div><div class="point-outer point-pre"><div class="point-inner"></div></div></div><div id="st_mask" onclick="closeMask()" style="width: 100%; height: 100%; background: rgba(0, 0, 0, 0.4); position: fixed; left: 0px; top: 0px; display: none; z-index: 1;"></div><div id="st_confirmBox" style="width: 100%; position: fixed; left: 0px; top: 34%; text-align: center; display: none; z-index: 2;"><div id="st_confirm" style="width: 80%; margin: 0px auto; background: rgb(255, 255, 255); border-radius: 3px; overflow: hidden; padding-top: 20px; text-align: center;"><span id="st_confirm_text" style="background: rgb(255, 255, 255); overflow: hidden; padding: 15px 8px 30px; text-align: center; display: block;"></span><span class="st_confirm_btn cancel" style="background: rgb(255, 255, 255); color: rgb(141, 141, 141); padding: 8px; text-align: center; display: block; width: 50%; margin: 0px auto; float: left; box-sizing: border-box; border-top: 1px solid rgb(207, 207, 207); overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></span><span class="st_confirm_btn success" style="background: rgb(27, 121, 248); color: rgb(255, 255, 255); padding: 8px; text-align: center; display: block; width: 50%; margin: 0px auto; float: left; box-sizing: border-box; border-top: 1px solid rgb(27, 121, 248); overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></span><div style="clear: both; display: block;"></div></div></div><div id="st_alertBox" style="width: 100%; position: fixed; left: 0px; top: 34%; text-align: center; display: none; z-index: 2;"><div id="st_alert" style="width: 80%; margin: 0px auto; background: rgb(255, 255, 255); border-radius: 2px; overflow: hidden; padding-top: 20px; text-align: center;"><span id="st_alert_text" style="background: rgb(255, 255, 255); overflow: hidden; padding: 15px 8px 30px; text-align: center; display: block;"></span><span id="st_alert_btn" onclick="closeMask()" style="background: rgb(27, 121, 248); color: rgb(255, 255, 255); padding: 8px; text-align: center; display: block; width: 72%; margin: 0px auto 20px; border-radius: 2px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;"></span></div></div><div id="st_toastBox" style="width: 100%; position: fixed; left: 0px; bottom: 10%; text-align: center; display: none;"><span id="st_toastContent" style="color: rgb(255, 255, 255); background: rgba(0, 0, 0, 0.8); padding: 8px 24px; border-radius: 4px; max-width: 80%; display: inline-block; font-size: 16px;"></span></div> <div class="report-box">  <div class="pos-boxer">      <div class="pos-content">          <div class="box-title">              <p>举报</p>              <svg class="icon btn-close" aria-hidden="true">                    <use xlink:href="#csdnc-times"></use>              </svg>          </div>          <div class="box-header">              <div class="box-top"><span>选择你想要举报的内容（必选）</span></div>              <div class="box-botoom">                  <ul>                      <li data="1" type="nei">内容涉黄</li>                      <li data="2" type="nei">政治相关</li>                      <li data="3" type="nei">内容抄袭</li>                      <li data="4" type="nei">涉嫌广告</li>                      <li data="5" type="nei">内容侵权</li>                      <li data="6" type="nei">侮辱谩骂</li>                      <li data="8" type="nei">样式问题</li>                      <li data="7" type="nei">其他</li>                  </ul>              </div>          </div>          <div>          <div class="box-content">          </div>          <div class="box-content">          </div>                    <div class="box-content" style="display:none;">                  <div class="box-content-top">                          <span>原文链接（必填）</span>                      </div>                      <div class="box-content-bottom" style="padding-bottom: 16px;">                        <div class="box-input" style="height: 32px;line-height: 32px;">                        <input class="content-input" type="text" id="originalurl" name="originalurl" placeholder="请输入被侵权原文链接">                        </div>                      </div>          </div>          <div class="box-content">          </div>          <div class="box-content" style="display:none;">                  <div class="box-content-top">                          <span>请选择具体原因（必选）</span>                      </div>                  <div class="box-content-bottom">                          <ul>                              <li sub_type="1">包含不实信息</li>                              <li sub_type="2">涉及个人隐私</li>                          </ul>                      </div>          </div>          <div class="box-content" style="display:none;">                  <div class="box-content-top">                          <span>请选择具体原因（必选）</span>                      </div>                  <div class="box-content-bottom">                          <ul>                              <li sub_type="1">侮辱谩骂</li>                              <li sub_type="2">诽谤</li>                          </ul>                  </div>          </div>          <div class="box-content" style="display:none;">                <div class="box-content-top">                        <span>请选择具体原因（必选）</span>                    </div>                <div class="box-content-bottom">                        <ul>                            <li sub_type="1">搬家样式</li>                            <li sub_type="2">博文样式</li>                        </ul>                </div>          </div>          <div class="box-content" style="display:none;">          </div>          </div>            <div id="cllcont" style="display:none;">            <div class="box-content-top">              <span class="box-content-span">补充说明（选填）</span>            </div>                <div class="box-content-bottom">                  <div class="box-input">                    <textarea class="ipt ipt-textarea" style="padding:0;" name="description" placeholder="请详细描述您的举报内容"></textarea>                  </div>                </div>            </div>            </div>      <div class="pos-footer">          <p class="btn-close">取消</p>          <p class="box-active">确定</p>      </div>  </div></div><div class="imgViewDom disnone" style="display: none;"><img src="https://blog.csdn.net/HUSTHY/article/details/105882989"></div><style>.imgViewDom{display:none;position:fixed;top:0;left:0;height:100%;width:100%;z-index:99999999;background: rgba(255, 255, 255,0.8);overflow: auto;display:-webkit-box;-webkit-box-align:center;-webkit-box-pack:center;display:-moz-box;-moz-box-align:center;-moz-box-pack:center;display:-o-box;-o-box-align:center;-o-box-pack:center;display:-ms-box;-ms-box-align:center;-ms-box-pack:center; display:box;box-align:center;box-pack:center;}.imgViewDom img{cursor: zoom-out;}</style><div>
  <div class="csdn-side-toolbar " style="bottom: 64px !important; left: 1296px;">
    
    <a class="option-box" data-type="guide">
      <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/guide.png" alt="" srcset="">
      <span class="show-txt">新手<br>引导</span>
    </a>
    
    
    
    
    <a class="option-box" data-type="cs">
      <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/kefu.png" alt="" srcset="">
      <span class="show-txt">客服</span>
    </a>
    
    
    
    <a class="option-box" data-type="report">
      <span class="show-txt" style="display:flex;opacity:100;">举报</span>
    </a>
    
    
    <a class="option-box" data-type="gotop">
      <img src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/fanhuidingbucopy.png" alt="" srcset="">
      <span class="show-txt">返回<br>顶部</span>
    </a>
    
  </div>
  </div><svg aria-hidden="true" style="position: absolute; width: 0px; height: 0px; overflow: hidden;"><symbol id="sousuo" viewBox="0 0 1024 1024"><path d="M719.6779726 653.55865555l0.71080936 0.70145709 191.77828505 191.77828506c18.25658185 18.25658185 18.25658185 47.86273439 0 66.12399318-18.26593493 18.26125798-47.87208744 18.26125798-66.13334544 0l-191.77828505-191.77828506c-0.2338193-0.2338193-0.4676378-0.4676378-0.69678097-0.71081014-58.13206223 44.25257003-130.69075187 70.51978897-209.38952657 70.51978894C253.06424184 790.19776156 98.14049639 635.27869225 98.14049639 444.17380511S253.06424184 98.14049639 444.16912898 98.14049639c191.10488633 0 346.02863258 154.92374545 346.02863259 346.02863259 0 78.6987747-26.27189505 151.25746514-70.51978897 209.38952657z m-275.50884362 43.11621045c139.45428506 0 252.50573702-113.05145197 252.50573702-252.50573702s-113.05145197-252.50573702-252.50573702-252.50573783-252.50573702 113.05145197-252.50573783 252.50573783 113.05145197 252.50573702 252.50573783 252.50573702z"></path></symbol><symbol id="gonggong_csdnlogo_" viewBox="0 0 4096 1024"><path d="M1234.16069807 690.46341551c62.96962316 23.02318413 194.30703694 45.91141406 300.51598128 45.91141406 114.44114969 0 178.13952547-31.68724287 183.2407937-80.86454822 4.642424-44.8587714-42.21366937-50.93170978-171.44579784-81.53931916-178.57137886-43.77913792-292.49970264-111.55313011-281.32549604-219.86735976 12.9825927-125.75031047 181.27046257-220.78504823 439.49180199-220.78504822 125.88526465 0 247.93783044 8.87998544 311.17736197 29.60894839l-21.7006331 158.57116851c-41.05306337-14.27815288-198.1937175-34.11641822-304.48363435-34.11641822-107.7744129 0-163.56447339 33.90049151-167.42416309 71.06687432-4.85835069 47.04502922 51.14763648 49.23128703 191.14910897 86.50563321 189.58364043 48.09767188 272.47250144 115.81768239 261.6221849 220.81203906-12.71268432 123.51007099-164.13128096 228.53141851-466.48263918 228.53141851-125.85827383 0-234.33444849-22.96920244-294.09216204-45.93840492l19.730302-157.86940672zM3010.8325562 172.75216735c688.40130256-129.79893606 747.80813523 103.42888812 726.53935551 309.80082928l-40.08139323 381.78539207h-218.51781789l36.57258439-348.20879061c7.90831529-76.68096846 57.13960232-226.66905073-180.54170997-221.05495659-82.26807176 1.99732195-123.05122675 13.2794919-123.05122677 13.27949188s-7.15257186 92.65954408-15.81663059 161.13529804l-41.43093509 394.84895728h-214.3072473l42.53755943-389.15389062 28.09746151-302.43233073z m-869.48282929-18.05687008c49.12332368-5.34418577 124.58970448-10.76934404 228.45044598-10.76934405 173.38913812 0 313.57954648 30.17575597 400.38207891 93.63121421 77.94953781 59.16391512 129.82592689 154.95439631 115.4668015 293.74128117-13.25250106 129.15115596-80.405704 219.57046055-178.16651631 275.4954752-89.44763445 52.74009587-202.16137055 75.27744492-371.66382812 75.27744493-99.94707012 0-195.27870708-5.39816743-267.77609576-16.14052064L2141.37671774 154.69529727z m143.26736381 569.85754561c16.70732823 3.23890047 38.67786969 6.45081009 81.99816339 6.45081009 173.44311979 0 295.7386031-85.23706385 308.01943403-205.07638097 17.84094339-173.2271931-90.63523129-233.79463176-273.39018992-232.74198912-23.67096422 0-56.57279475 0-73.98188473 3.1849188l-42.6725136 428.15565036z" fill="#262626"></path><path d="M1109.8678928 870.30336371c-41.10704503 14.25116203-126.26313639 23.96786342-245.23874671 23.96786342-342.13585224 0-526.8071603-160.59548129-504.97157302-372.90540663C385.78470347 268.40769434 659.36382925 126.08500985 958.9081404 126.08500985c116.00661824 0 184.32042718 9.33882968 248.31570215 24.99351522l-20.5400271 170.42014604c-42.56455024-14.33213455-142.32268451-27.50366309-223.07926938-27.50366311-176.25016686 0-325.94134993 52.49717834-343.10752238 218.57179958-15.30380469 148.50358623 89.7715245 219.48948804 288.04621451 219.48948804 69.0155707 0 170.77102691-9.8786464 217.81605614-24.15679928l-16.49140154 162.40386737z" fill="#CA0C16"></path></symbol><symbol id="gonggong_csdnlogodanse_" viewBox="0 0 4096 1024"><path d="M1229.41995733 690.46341551c62.96962316 23.02318413 194.30703694 45.91141406 300.51598128 45.91141406 114.44114969 0 178.13952547-31.68724287 183.2407937-80.86454822 4.642424-44.8587714-42.21366937-50.93170978-171.44579784-81.53931916-178.57137886-43.77913792-292.49970264-111.55313011-281.32549604-219.86735976 12.9825927-125.75031047 181.27046257-220.78504823 439.49180199-220.78504822 125.88526465 0 247.93783044 8.87998544 311.17736197 29.60894839l-21.7006331 158.57116851c-41.05306337-14.27815288-198.1937175-34.11641822-304.48363435-34.11641822-107.7744129 0-163.56447339 33.90049151-167.42416309 71.06687432-4.85835069 47.04502922 51.14763648 49.23128703 191.14910897 86.50563321 189.58364043 48.09767188 272.47250144 115.81768239 261.6221849 220.81203906-12.71268432 123.51007099-164.13128096 228.53141851-466.48263918 228.53141851-125.85827383 0-234.33444849-22.96920244-294.09216204-45.93840492l19.730302-157.86940672zM3006.09181546 172.75216735c688.40130256-129.79893606 747.80813523 103.42888812 726.53935551 309.80082928l-40.08139323 381.78539207h-218.51781789l36.57258439-348.20879061c7.90831529-76.68096846 57.13960232-226.66905073-180.54170997-221.05495659-82.26807176 1.99732195-123.05122675 13.2794919-123.05122677 13.27949188s-7.15257186 92.65954408-15.81663059 161.13529804l-41.43093509 394.84895728h-214.3072473l42.53755943-389.15389062 28.09746151-302.43233073z m-869.48282929-18.05687008c49.12332368-5.34418577 124.58970448-10.76934404 228.45044598-10.76934405 173.38913812 0 313.57954648 30.17575597 400.38207891 93.63121421 77.94953781 59.16391512 129.82592689 154.95439631 115.4668015 293.74128117-13.25250106 129.15115596-80.405704 219.57046055-178.16651631 275.4954752-89.44763445 52.74009587-202.16137055 75.27744492-371.66382812 75.27744493-99.94707012 0-195.27870708-5.39816743-267.77609576-16.14052064L2136.635977 154.69529727z m143.26736381 569.85754561c16.70732823 3.23890047 38.67786969 6.45081009 81.99816339 6.45081009 173.44311979 0 295.7386031-85.23706385 308.01943403-205.07638097 17.84094339-173.2271931-90.63523129-233.79463176-273.39018992-232.74198912-23.67096422 0-56.57279475 0-73.98188473 3.1849188l-42.6725136 428.15565036z m-1174.74919792 145.75052083c-41.10704503 14.25116203-126.26313639 23.96786342-245.23874671 23.96786342-342.13585224 0-526.8071603-160.59548129-504.97157303-372.90540663C381.04396273 268.40769434 654.62308851 126.08500985 954.16739966 126.08500985c116.00661824 0 184.32042718 9.33882968 248.31570215 24.99351522l-20.5400271 170.42014604c-42.56455024-14.33213455-142.32268451-27.50366309-223.07926938-27.50366311-176.25016686 0-325.94134993 52.49717834-343.10752238 218.57179958-15.30380469 148.50358623 89.7715245 219.48948804 288.04621451 219.48948804 69.0155707 0 170.77102691-9.8786464 217.81605614-24.15679928l-16.49140154 162.40386737z"></path></symbol><symbol id="xieboke1" viewBox="0 0 1024 1024"><path d="M204.70021457 751.89799169h657.99199211a33.6932867 33.6932867 0 0 1 0 67.33536736H163.68452703a33.53966977 33.53966977 0 0 1-18.74125054-5.68382181c-18.63883902-9.4218307-18.17798882-29.44322156-15.20806401-39.17228615C199.0675982 570.27171976 309.41567149 409.58853908 435.38145354 290.12586836A243.22661203 243.22661203 0 0 1 536.97336934 234.20935065c138.10150976-33.79569759 228.3257813-29.95527721 318.60125827-28.52152054-17.15387692 20.48224105-36.20236071 41.6301547-57.29906892 62.93168529-3.1747472 3.22595323-164.67721739 19.91897936-187.97576692 47.05794871-23.29854894 27.13896932 129.60138005 7.37360691 125.19769798 11.11161576-21.6599699 18.33160576-44.90731339 36.4071831-69.94685287 53.8682939-4.50609297 3.1747472-149.52035944-0.35843931-174.61110436 27.85584737-25.19315641 28.16308124 101.89914903 18.12678338 96.0617103 21.40394206-67.43777825 37.63611797-125.96578207 64.62147036-212.70807253 93.8086635-57.65750823 19.4069231-121.8181284 133.13456658-146.5504346 179.06599187a435.75967738 435.75967738 0 0 0-23.04252112 49.10617311z" fill="#CA0C16"></path></symbol><symbol id="gitchat" viewBox="0 0 1024 1024"><path d="M892.08971773 729.08552746h-108.597062v-162.89559374H403.40293801v-108.59706198h488.68677972v271.49265572z m-651.58237345 54.298531V783.49265572h488.68678045v108.59706201H131.91028227V131.91028227h760.17943546v217.19412473h-108.597062V240.50734428H240.50734428v542.87671418z m542.98531145 0h108.597062v108.59706199h-108.597062v-108.59706199z" fill="#FF9100"></path></symbol><symbol id="toolbar-memberhead" viewBox="0 0 1303 1024"><path d="M1061.51168438 433.79527648A78.51879902 78.51879902 0 1 1 1129.35192643 472.74060007h-1.80593246l-48.05350474 403.97922198c-4.55409058 38.16013652-39.41643684 67.133573-80.79584389 67.13357302H319.35199503c-41.30088817 0-76.00619753-28.81639958-80.717325-66.97653526L189.01078861 472.74060007H187.12633728a78.51879902 78.51879902 0 1 1 67.76172401-38.86680556l193.31328323 119.81968805 158.13686148-336.06046024A78.5973179 78.5973179 0 0 1 658.23913228 80.14660493a78.51879902 78.51879902 0 0 1 51.58685077 137.721974l158.13686147 335.82490362 193.54883986-119.89820607z" fill="#FDD840"></path><path d="M1050.8331274 394.22180104a78.51879902 78.51879902 0 1 1 78.51879903 78.51879903h-1.80593246l-48.05350474 403.97922198c-4.55409058 38.16013652-39.41643684 67.133573-80.79584389 67.13357302H659.02432018C658.47468805 793.25433807 658.23913228 505.32590231 658.23913228 80.14660493a78.51879902 78.51879902 0 0 1 51.58685077 137.721974l158.13686147 335.82490362 193.54883986-119.89820607A78.51879902 78.51879902 0 0 1 1050.8331274 394.22180104z" fill="#FFBE00"></path></symbol><symbol id="toolbar-m-memberhead" viewBox="0 0 1303 1024"><path d="M1062.74839935 433.79527648A78.51879902 78.51879902 0 1 1 1130.58864141 472.74060007h-1.80593246l-48.05350474 403.97922198c-4.55409058 38.16013652-39.41643685 67.133573-80.79584389 67.13357302H320.58871c-41.30088817 0-76.00619753-28.81639958-80.71732499-66.97653526L190.24750358 472.74060007H188.36305226a78.51879902 78.51879902 0 1 1 67.761724-38.86680556l193.31328324 119.81968805 158.13686147-336.06046024A78.5973179 78.5973179 0 0 1 659.47584726 80.14660493a78.51879902 78.51879902 0 0 1 51.58685076 137.721974l158.13686148 335.82490362 193.54883985-119.89820607z" fill="#D6D6D6"></path><path d="M1052.06984238 394.22180104a78.51879902 78.51879902 0 1 1 78.51879903 78.51879903h-1.80593246l-48.05350474 403.97922198c-4.55409058 38.16013652-39.41643685 67.133573-80.79584389 67.13357302H660.26103515C659.71140302 793.25433807 659.47584726 505.32590231 659.47584726 80.14660493a78.51879902 78.51879902 0 0 1 51.58685076 137.721974l158.13686148 335.82490362 193.54883985-119.89820607A78.51879902 78.51879902 0 0 1 1052.06984238 394.22180104z" fill="#C1C1C1"></path></symbol><symbol id="csdnc-upload" viewBox="0 0 1024 1024"><path d="M216.37466416 723.16095396v84.46438188h591.25067168v-84.46438188c0-23.32483876 18.90735218-42.23219094 42.23219093-42.23219021s42.23219094 18.90735218 42.23219096 42.23219021v84.46438188c0 46.64967827-37.81470362 84.46438188-84.46438189 84.46438189H216.37466416c-46.64967827 0-84.46438188-37.81470362-84.46438189-84.4643819v-84.46438187c0-23.32483876 18.90735218-42.23219094 42.23219096-42.23219021s42.23219094 18.90735218 42.23219094 42.23219021zM469.76780906 275.55040991L246.55378774 499.53305726a42.30820888 42.30820888 0 0 1-59.99082735 0c-16.56346508-16.62259056-16.56346508-43.57095155 0-60.19354139L480.51167818 144.38144832A42.21952103 42.21952103 0 0 1 512 131.93984464a42.20262858 42.20262858 0 0 1 31.48409853 12.44160369l293.95294108 294.95806754c16.56346508 16.62259056 16.56346508 43.57095155 0 60.19354139a42.30820888 42.30820888 0 0 1-59.99082735 0L554.23219094 275.55040991V680.92876375c0 23.32483876-18.90735218 42.23219094-42.23219094 42.23219021s-42.23219094-18.90735218-42.23219094-42.23219021V275.55040991z"></path></symbol></svg><iframe class="bdSug_sd" style="display: none; position: absolute; border-width: 0px;" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/saved_resource(6).html"></iframe><div id="bdSug_1608703155376" class="bdSug_wpr" style="display: none;"></div><ins class="adsbygoogle adsbygoogle-noablate" data-adsbygoogle-status="done" style="display: none !important;"><ins id="aswift_2_expand" style="display:inline-table;border:none;height:0px;margin:0;padding:0;position:relative;visibility:visible;width:0px;background-color:transparent;" tabindex="0" title="Advertisement" aria-label="Advertisement"><ins id="aswift_2_anchor" style="display:block;border:none;height:0px;margin:0;padding:0;position:relative;visibility:visible;width:0px;background-color:transparent;"><iframe id="aswift_2" name="aswift_2" style="left:0;position:absolute;top:0;border:0;width:undefinedpx;height:undefinedpx;" sandbox="allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation" frameborder="0" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/ads(2).html" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" allowfullscreen="true" data-google-container-id="a!2" data-load-complete="true"></iframe></ins></ins></ins><iframe id="google_osd_static_frame_8569239346183" name="google_osd_static_frame" style="display: none; width: 0px; height: 0px;" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/saved_resource(7).html"></iframe><div class="login-mark" style="display: none;"></div><div id="passportbox" class="login-box" style="display: none;"><iframe width="410" height="427" name="passport_iframe" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/login.html" frameborder="0" scrolling="no"></iframe></div></body><iframe id="google_esf" name="google_esf" src="./bert模型简介、transformers中bert模型源码阅读、分类任务实战和难点总结_HUSTHY的博客-CSDN博客_files/zrt_lookup.html" data-ad-client="ca-pub-1076724771190722" style="display: none;"></iframe></html>